<!DOCTYPE html>
<!--[if IE 6]><html class="ie lt-ie8"><![endif]-->
<!--[if IE 7]><html class="ie lt-ie8"><![endif]-->
<!--[if IE 8]><html class="ie ie8"><![endif]-->
<!--[if IE 9]><html class="ie ie9"><![endif]-->
<!--[if !IE]><!--> <html> <!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0,user-scalable=no">

  <!-- Start of Baidu Transcode -->
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta name="applicable-device" content="pc,mobile">
  <meta name="MobileOptimized" content="width"/>
  <meta name="HandheldFriendly" content="true"/>
  <meta name="mobile-agent" content="format=html5;url=https://www.jianshu.com/p/b4128bc79df0">
  <!-- End of Baidu Transcode -->

    <meta name="description"  content="秋招基本结束，让我们继续学习！长期有耐心！ 今天我们要学习的模型是xDeepFM模型，论文地址为：https://arxiv.org/abs/1803.05170。文中包含我个人的一些理解，如有不对的地方，欢迎大家指正！废话不多说，我们进入正题！ 1、引言 对于预测性的系统来说，特征工程起到了至关重要的作用。特征工程中，挖掘交叉特征是至关重要的。交叉特征指的是两个或多个原始特征之间的交叉组合...">

  <meta name="360-site-verification" content="604a14b53c6b871206001285921e81d8" />
  <meta property="wb:webmaster" content="294ec9de89e7fadb" />
  <meta property="qc:admins" content="104102651453316562112116375" />
  <meta property="qc:admins" content="11635613706305617" />
  <meta property="qc:admins" content="1163561616621163056375" />
  <meta name="google-site-verification" content="cV4-qkUJZR6gmFeajx_UyPe47GW9vY6cnCrYtCHYNh4" />
  <meta name="google-site-verification" content="HF7lfF8YEGs1qtCE-kPml8Z469e2RHhGajy6JPVy5XI" />
  <meta http-equiv="mobile-agent" content="format=html5; url=https://www.jianshu.com/p/b4128bc79df0">

  <!-- Apple -->
  <meta name="apple-mobile-web-app-title" content="简书">

    <!--  Meta for Smart App Banner -->
  <meta name="apple-itunes-app" content="app-id=888237539, app-argument=jianshu://notes/34140712">
  <!-- End -->

  <!--  Meta for Twitter Card -->
  <meta content="summary" property="twitter:card">
  <meta content="@jianshucom" property="twitter:site">
  <meta content="推荐系统遇上深度学习(二十二)--DeepFM升级版XDeepFM模型强势来袭！" property="twitter:title">
  <meta content="秋招基本结束，让我们继续学习！长期有耐心！ 今天我们要学习的模型是xDeepFM模型，论文地址为：https://arxiv.org/abs/1803.05170。文中包含我..." property="twitter:description">
  <meta content="https://www.jianshu.com/p/b4128bc79df0" property="twitter:url">
  <!-- End -->

  <!--  Meta for OpenGraph -->
  <meta property="fb:app_id" content="865829053512461">
  <meta property="og:site_name" content="简书">
  <meta property="og:title" content="推荐系统遇上深度学习(二十二)--DeepFM升级版XDeepFM模型强势来袭！">
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://www.jianshu.com/p/b4128bc79df0">
  <meta property="og:description" content="秋招基本结束，让我们继续学习！长期有耐心！ 今天我们要学习的模型是xDeepFM模型，论文地址为：https://arxiv.org/abs/1803.05170。文中包含我个人的一些理解，如有...">
  <!-- End -->

  <!--  Meta for Facebook Applinks -->
  <meta property="al:ios:url" content="jianshu://notes/34140712" />
  <meta property="al:ios:app_store_id" content="888237539" />
  <meta property="al:ios:app_name" content="简书" />

  <meta property="al:android:url" content="jianshu://notes/34140712" />
  <meta property="al:android:package" content="com.jianshu.haruki" />
  <meta property="al:android:app_name" content="简书" />
  <!-- End -->


    <title>推荐系统遇上深度学习(二十二)--DeepFM升级版XDeepFM模型强势来袭！ - 简书</title>

  <meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="b0HqLTkgTtbUnEE7W/xtiNacwm2i0JlmgKrgHjwsov3LSgEzOWM6MyHl0qS3PU6Y5XL15+ZrUKjkGYWoB2EuUQ==" />

  <link rel="stylesheet" media="all" href="//cdn2.jianshu.io/assets/web-274d6a76417c1f7a7da5.css" />
  
  <link rel="stylesheet" media="all" href="//cdn2.jianshu.io/assets/web/pages/notes/show/entry-aa75deb505b1b600256a.css" />

  <link href="//cdn2.jianshu.io/assets/favicons/favicon-e743bfb1821442341c3ab15bdbe804f7ad97676bd07a770ccc9483473aa76f06.ico" rel="shortcut icon" type="image/x-icon">
      <link rel="apple-touch-icon-precomposed" href="//cdn2.jianshu.io/assets/apple-touch-icons/57-a6f1f1ee62ace44f6dc2f6a08575abd3c3b163288881c78dd8d75247682a4b27.png" sizes="57x57" />
      <link rel="apple-touch-icon-precomposed" href="//cdn2.jianshu.io/assets/apple-touch-icons/72-fb9834bcfce738fd7b9c5e31363e79443e09a81a8e931170b58bc815387c1562.png" sizes="72x72" />
      <link rel="apple-touch-icon-precomposed" href="//cdn2.jianshu.io/assets/apple-touch-icons/76-49d88e539ff2489475d603994988d871219141ecaa0b1a7a9a1914f4fe3182d6.png" sizes="76x76" />
      <link rel="apple-touch-icon-precomposed" href="//cdn2.jianshu.io/assets/apple-touch-icons/114-24252fe693524ed3a9d0905e49bff3cbd0228f25a320aa09053c2ebb4955de97.png" sizes="114x114" />
      <link rel="apple-touch-icon-precomposed" href="//cdn2.jianshu.io/assets/apple-touch-icons/120-1bb7371f5e87f93ce780a5f1a05ff1b176828ee0d1d130e768575918a2e05834.png" sizes="120x120" />
      <link rel="apple-touch-icon-precomposed" href="//cdn2.jianshu.io/assets/apple-touch-icons/152-bf209460fc1c17bfd3e2b84c8e758bc11ca3e570fd411c3bbd84149b97453b99.png" sizes="152x152" />

  <!-- Start of 访问统计 -->
    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?0c0e9d9b1e7d617b3e6842e85b9fb068";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>

  <!-- End of 访问统计 -->
</head>

  <!-- 只给10%的用户添加代码 -->
  <!-- ###第四范式-智能推荐：代码直接复制 无需修改参数### -->
  <!-- ###功能：上报内容并反馈用户行为### -->
  <!--
    <script charset="utf-8" id="ParadigmSDKv3" src="https://nbrecsys.4paradigm.com/sdk/js/ParadigmSDK_v3.js">
    </script>
    <script>
      ParadigmSDKv3.init("5cc57c5e8add401aa5533ff26dde2532");
      ParadigmSDKv3.trackDetailPageShow(524);
    </script>
  -->
  <body lang="zh-CN" class="reader-black-font">
    <!-- 全局顶部导航栏 -->
<nav class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="width-limit">
    <!-- 左上方 Logo -->
    <a class="logo" href="/"><img src="//cdn2.jianshu.io/assets/web/nav-logo-4c7bbafe27adc892f3046e6978459bac.png" alt="Nav logo" /></a>

    <!-- 右上角 -->
      <!-- 未登录显示登录/注册/写文章 -->
      <a class="btn write-btn" target="_blank" href="/writer#/">
        <i class="iconfont ic-write"></i>写文章
</a>      <a class="btn sign-up" id="sign_up" href="/sign_up">注册</a>
      <a class="btn log-in" id="sign_in" href="/sign_in">登录</a>

    <!-- 如果用户登录，显示下拉菜单 -->

    <div id="view-mode-ctrl">
    </div>
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#menu" aria-expanded="false">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
      </div>
      <div class="collapse navbar-collapse" id="menu">
        <ul class="nav navbar-nav">
            <li class="tab ">
              <a href="/">
                <span class="menu-text">首页</span><i class="iconfont ic-navigation-discover menu-icon"></i>
</a>            </li>
            <li class="tab ">
              <a id="web-nav-app-download-btn" class="app-download-btn" href="/apps?utm_medium=desktop&amp;utm_source=navbar-apps"><span class="menu-text">下载App</span><i class="iconfont ic-navigation-download menu-icon"></i></a>
            </li>
          <li class="search">
            <form target="_blank" action="/search" accept-charset="UTF-8" method="get"><input name="utf8" type="hidden" value="&#x2713;" />
              <input type="text" name="q" id="q" value="" autocomplete="off" placeholder="搜索" class="search-input" />
              <a class="search-btn" href="javascript:void(null)"><i class="iconfont ic-search"></i></a>
</form>          </li>
        </ul>
      </div>
    </div>
  </div>
</nav>

    
<div class="note">
  <div id="note-fixed-ad-container">
    <div id="fixed-ad-container">
      <div id="write-notes-ad"></div>
      <div id="youdao-fixed-ad"></div>
      <div id="yuxi-fixed-ad"></div>
      <div id="_so_pdsBy_0"></div>
    </div>
  </div>
  <div class="post">
    <div class="article">
        <h1 class="title">推荐系统遇上深度学习(二十二)--DeepFM升级版XDeepFM模型强势来袭！</h1>

        <!-- 作者区域 -->
        <div class="author">
          <a class="avatar" href="/u/c5df9e229a67">
            <img src="//upload.jianshu.io/users/upload_avatars/4155986/0b79def0-fd6c-44d8-9410-1c13d3a2cf7e.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/96/h/96" alt="96" />
</a>          <div class="info">
            <span class="name"><a href="/u/c5df9e229a67">石晓文的学习日记</a></span>
            <!-- 关注用户按钮 -->
            <div props-data-classes="user-follow-button-header" data-author-follow-button></div>
            <!-- 文章数据信息 -->
            <div class="meta">
              <!-- 简书钻 -->
                <span class="jsd-meta">
                  <i class="iconfont ic-paid1"></i> 0.3
                </span>
              <!-- 如果文章更新时间大于发布时间，那么使用 tooltip 显示更新时间 -->
                <span class="publish-time" data-toggle="tooltip" data-placement="bottom" title="最后编辑于 2018.09.22 14:25">2018.09.22 14:20*</span>
              <span class="wordage">字数 3733</span>
            </div>
          </div>
          <!-- 如果是当前作者，加入编辑按钮 -->
        </div>


        <!-- 文章内容 -->
        <div data-note-content class="show-content">
          <div class="show-content-free">
            <p>秋招基本结束，让我们继续学习！长期有耐心！</p>
<p>今天我们要学习的模型是xDeepFM模型，论文地址为：<a href="https://arxiv.org/abs/1803.05170" target="_blank" rel="nofollow">https://arxiv.org/abs/1803.05170</a>。文中包含我个人的一些理解，如有不对的地方，欢迎大家指正！废话不多说，我们进入正题！</p>
<h1>1、引言</h1>
<p>对于预测性的系统来说，特征工程起到了至关重要的作用。特征工程中，挖掘交叉特征是至关重要的。交叉特征指的是两个或多个原始特征之间的交叉组合。例如，在新闻推荐场景中，一个三阶交叉特征为AND(user_organization=msra,item_category=deeplearning,time=monday_morning),它表示当前用户的工作单位为微软亚洲研究院，当前文章的类别是与深度学习相关的，并且推送时间是周一上午。</p>
<p>传统的推荐系统中，挖掘交叉特征主要依靠人工提取，这种做法主要有以下三种缺点：</p>
<p>1）重要的特征都是与应用场景息息相关的，针对每一种应用场景，工程师们都需要首先花费大量时间和精力深入了解数据的规律之后才能设计、提取出高效的高阶交叉特征，因此人力成本高昂；<br>
2）原始数据中往往包含大量稀疏的特征，例如用户和物品的ID，交叉特征的维度空间是原始特征维度的乘积，因此很容易带来维度灾难的问题；<br>
3）人工提取的交叉特征无法泛化到未曾在训练样本中出现过的模式中。</p>
<p>因此自动学习特征间的交互关系是十分有意义的。目前大部分相关的研究工作是基于因子分解机的框架，利用多层全连接神经网络去自动学习特征间的高阶交互关系，例如FNN、PNN和DeepFM等。其缺点是模型学习出的是隐式的交互特征，其形式是未知的、不可控的；同时它们的特征交互是发生在<strong>元素级（bit-wise）</strong>而不是<strong>特征向量之间（vector-wise）</strong>，这一点违背了因子分解机的初衷。来自Google的团队在KDD 2017 AdKDD&amp;TargetAD研讨会上提出了DCN模型，旨在显式（explicitly）地学习高阶特征交互，其优点是模型非常轻巧高效，但缺点是最终模型的表现形式是一种很特殊的向量扩张，同时特征交互依旧是发生在元素级上。</p>
<p>我们用下图来回顾一下DCN的实现：</p>
<div class="image-package">
<div class="image-container" style="max-width: 588px; max-height: 554px;">
<div class="image-container-fill" style="padding-bottom: 94.22%;"></div>
<div class="image-view" data-width="588" data-height="554"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-ecee2d8901361e99" data-original-width="588" data-original-height="554" data-original-format="image/png" data-original-filesize="90735"></div>
</div>
<div class="image-caption"></div>
</div>
<p>下面是我对文中提到的两个重要概念的理解：</p>
<p><strong>bit-wise VS vector-wise</strong><br>
假设隐向量的维度为3维，如果两个特征(对应的向量分别为(a1,b1,c1)和(a2,b2,c2)的话）在进行交互时，交互的形式类似于f(w1 * a1 * a2,w2 * b1 * b2 ,w3 * c1 * c2)的话，此时我们认为特征交互是发生在<strong>元素级（bit-wise）</strong>上。如果特征交互形式类似于 f(w * (a1 * a2 ,b1 * b2,c1 * c2))的话，那么我们认为特征交互是发生在<strong>特征向量级（vector-wise）</strong>。</p>
<p><strong>explicitly VS implicitly</strong><br>
显式的特征交互和隐式的特征交互。以两个特征为例xi和xj，在经过一系列变换后，我们可以表示成 wij * (xi * xj)的形式，就可以认为是显式特征交互，否则的话，是隐式的特征交互。</p>
<p>微软亚洲研究院社会计算组提出了一种极深因子分解机模型（xDeepFM），不仅能同时以显式和隐式的方式自动学习高阶的特征交互，使特征交互发生在向量级，还兼具记忆与泛化的学习能力。</p>
<p>我们接下来就来看看xDeepFM这个模型是怎么做的吧！</p>
<h1>2、xDeepFM模型介绍</h1>
<h1>2.1 Compressed Interaction Network</h1>
<p>为了实现自动学习显式的高阶特征交互，同时使得交互发生在向量级上，文中首先提出了一种新的名为压缩交互网络（Compressed Interaction Network，简称CIN）的神经模型。在CIN中，隐向量是一个单元对象，因此我们将输入的原特征和神经网络中的隐层都分别组织成一个矩阵，记为X<sup>0和X</sup>k。CIN中每一层的神经元都是根据前一层的隐层以及原特征向量推算而来，其计算公式如下：</p>
<div class="image-package">
<div class="image-container" style="max-width: 511px; max-height: 124px;">
<div class="image-container-fill" style="padding-bottom: 24.27%;"></div>
<div class="image-view" data-width="511" data-height="124"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-f6fd001a226680f5.png" data-original-width="511" data-original-height="124" data-original-format="image/png" data-original-filesize="57294"></div>
</div>
<div class="image-caption"></div>
</div>
<p>其中点乘的部分计算如下：</p>
<div class="image-package">
<div class="image-container" style="max-width: 383px; max-height: 29px;">
<div class="image-container-fill" style="padding-bottom: 7.57%;"></div>
<div class="image-view" data-width="383" data-height="29"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-1f1a75dc0c18ed69.png" data-original-width="383" data-original-height="29" data-original-format="image/png" data-original-filesize="3688"></div>
</div>
<div class="image-caption"></div>
</div>
<p>我们来解释一下上面的过程，第k层隐层含有H_k条神经元向量。隐层的计算可以分成两个步骤：（1）根据前一层隐层的状态X<sup>k和原特征矩阵X</sup>0，计算出一个中间结果Z^k+1，它是一个三维的张量，如下图所示：</p>
<div class="image-package">
<div class="image-container" style="max-width: 485px; max-height: 463px;">
<div class="image-container-fill" style="padding-bottom: 95.46%;"></div>
<div class="image-view" data-width="485" data-height="463"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-89974f1fc48762af.png" data-original-width="485" data-original-height="463" data-original-format="image/png" data-original-filesize="55862"></div>
</div>
<div class="image-caption"></div>
</div>
<p>在这个中间结果上，我们用H<sup>k+1个尺寸为m*H</sup>k的卷积核生成下一层隐层的状态，该过程如图2所示。这一操作与计算机视觉中最流行的卷积神经网络大体是一致的，唯一的区别在于卷积核的设计。CIN中一个神经元相关的接受域是垂直于特征维度D的整个平面，而CNN中的接受域是当前神经元周围的局部小范围区域，因此CIN中经过卷积操作得到的特征图（Feature Map）是一个向量，而不是一个矩阵。</p>
<div class="image-package">
<div class="image-container" style="max-width: 467px; max-height: 457px;">
<div class="image-container-fill" style="padding-bottom: 97.86%;"></div>
<div class="image-view" data-width="467" data-height="457"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-576be6de0a1dbeb5.png" data-original-width="467" data-original-height="457" data-original-format="image/png" data-original-filesize="89291"></div>
</div>
<div class="image-caption"></div>
</div>
<p>如果你觉得原文中的图不够清楚的话，希望下图可以帮助你理解整个过程：</p>
<div class="image-package">
<div class="image-container" style="max-width: 700px; max-height: 351px;">
<div class="image-container-fill" style="padding-bottom: 50.24999999999999%;"></div>
<div class="image-view" data-width="1628" data-height="818"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-52d9f278c189208a.png" data-original-width="1628" data-original-height="818" data-original-format="image/png" data-original-filesize="117576"></div>
</div>
<div class="image-caption"></div>
</div>
<p>CIN的宏观框架可以总结为下图：</p>
<div class="image-package">
<div class="image-container" style="max-width: 460px; max-height: 478px;">
<div class="image-container-fill" style="padding-bottom: 103.91%;"></div>
<div class="image-view" data-width="460" data-height="478"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-865e97a5b034c18a.png" data-original-width="460" data-original-height="478" data-original-format="image/png" data-original-filesize="51229"></div>
</div>
<div class="image-caption"></div>
</div>
<p>可以看出，它的特点是，最终学习出的特征交互的阶数是由网络的层数决定的，每一层隐层都通过一个池化操作连接到输出层，从而保证了输出单元可以见到不同阶数的特征交互模式。同时不难看出，CIN的结构与循环神经网络RNN是很类似的，即每一层的状态是由前一层隐层的值与一个额外的输入数据计算所得。不同的是，CIN中不同层的参数是不一样的，而在RNN中是相同的；RNN中每次额外的输入数据是不一样的，而CIN中额外的输入数据是固定的，始终是X^0。</p>
<p>可以看到，CIN是通过（vector-wise）来学习特征之间的交互的，还有一个问题，就是它为什么是显式的进行学习？我们先从X<sup>1来开始看，X</sup>1的第h个神经元向量可以表示成：</p>
<div class="image-package">
<div class="image-container" style="max-width: 307px; max-height: 118px;">
<div class="image-container-fill" style="padding-bottom: 38.440000000000005%;"></div>
<div class="image-view" data-width="307" data-height="118"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-090532cfbf3593fc.png" data-original-width="307" data-original-height="118" data-original-format="image/png" data-original-filesize="8546"></div>
</div>
<div class="image-caption"></div>
</div>
<p>进一步，X^2的第h个神经元向量可以表示成：</p>
<div class="image-package">
<div class="image-container" style="max-width: 426px; max-height: 193px;">
<div class="image-container-fill" style="padding-bottom: 45.31%;"></div>
<div class="image-view" data-width="426" data-height="193"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-f41cc8ab14a3d724.png" data-original-width="426" data-original-height="193" data-original-format="image/png" data-original-filesize="20391"></div>
</div>
<div class="image-caption"></div>
</div>
<p>最后，第k层的第h个神经元向量可以表示成：</p>
<div class="image-package">
<div class="image-container" style="max-width: 561px; max-height: 194px;">
<div class="image-container-fill" style="padding-bottom: 34.58%;"></div>
<div class="image-view" data-width="561" data-height="194"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-173a66f80a7e4f4c.png" data-original-width="561" data-original-height="194" data-original-format="image/png" data-original-filesize="26099"></div>
</div>
<div class="image-caption"></div>
</div>
<p>因此，我们能够通过上面的式子对特征交互的形式进行一个很好的表示，它是显式的学习特征交叉。</p>
<h1>2.2 xDeepFM</h1>
<p>将CIN与线性回归单元、全连接神经网络单元组合在一起，得到最终的模型并命名为极深因子分解机xDeepFM，其结构如下图：</p>
<div class="image-package">
<div class="image-container" style="max-width: 700px; max-height: 690px;">
<div class="image-container-fill" style="padding-bottom: 65.59%;"></div>
<div class="image-view" data-width="1052" data-height="690"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-99a5bcc517d40903.png" data-original-width="1052" data-original-height="690" data-original-format="image/png" data-original-filesize="112867"></div>
</div>
<div class="image-caption"></div>
</div>
<p>集成的CIN和DNN两个模块能够帮助模型同时以显式和隐式的方式学习高阶的特征交互，而集成的线性模块和深度神经模块也让模型兼具记忆与泛化的学习能力。值得一提的是，为了提高模型的通用性，xDeepFM中不同的模块共享相同的输入数据。而在具体的应用场景下，不同的模块也可以接入各自不同的输入数据，例如，线性模块中依旧可以接入很多根据先验知识提取的交叉特征来提高记忆能力，而在CIN或者DNN中，为了减少模型的计算复杂度，可以只导入一部分稀疏的特征子集。</p>
<h1>3、Tensorflow充电</h1>
<p>在介绍xDeepFM的代码之前，我们先来进行充电，学习几个tf的函数以及xDeepFM关键过程的实现。</p>
<p><strong>tf.split</strong><br>
首先我们要实现第一步：<br>
</p><div class="image-package">
<div class="image-container" style="max-width: 485px; max-height: 463px;">
<div class="image-container-fill" style="padding-bottom: 95.46%;"></div>
<div class="image-view" data-width="485" data-height="463"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-89974f1fc48762af.png" data-original-width="485" data-original-height="463" data-original-format="image/png" data-original-filesize="55862"></div>
</div>
<div class="image-caption"></div>
</div><p></p>
<p>如何将两个二维的矩阵，相乘得到一个三维的矩阵？我们首先来看一下tf.split函数的原理:</p>
<pre><code>tf.split(
    value,
    num_or_size_splits,
    axis=0,
    num=None,
    name='split'
)
</code></pre>
<p>其中，value传入的就是需要切割的张量，axis是切割的维度，根据num_or_size_splits的不同形式，有两种切割方式：</p>
<ol>
<li>如果num_or_size_splits传入的是一个整数，这个整数代表这个张量最后会被切成几个小张量。此时，传入axis的数值就代表切割哪个维度（从0开始计数）。调用tf.split(my_tensor, 2，0)返回两个10 * 30 * 40的小张量。</li>
<li>如果num_or_size_splits传入的是一个向量，那么向量有几个分量就分成几份，切割的维度还是由axis决定。比如调用tf.split(my_tensor, [10, 5, 25], 2)，则返回三个张量分别大小为 20 * 30 * 10、20 * 30 * 5、20 * 30 * 25。很显然，传入的这个向量各个分量加和必须等于axis所指示原张量维度的大小 (10 + 5 + 25 = 40)。</li>
</ol>
<p>好了，从实际需求出发，我们来体验一下，假设我们的batch为2，embedding的size是3，field数量为4。我们先来生成两个这样的tensor(假设X^k的field也是4 )：</p>
<pre><code>arr1 = tf.convert_to_tensor(np.arange(1,25).reshape(2,4,3),dtype=tf.int32)
arr2 = tf.convert_to_tensor(np.arange(1,25).reshape(2,4,3),dtype=tf.int32)
</code></pre>
<p>生成的矩阵如下：</p>
<div class="image-package">
<div class="image-container" style="max-width: 154px; max-height: 277px;">
<div class="image-container-fill" style="padding-bottom: 179.87%;"></div>
<div class="image-view" data-width="154" data-height="277"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-573b9e5a2a17dc49.png" data-original-width="154" data-original-height="277" data-original-format="image/png" data-original-filesize="12643"></div>
</div>
<div class="image-caption"></div>
</div>
<p>在经过CIN的第一步之后，我们目标的矩阵大小应该是2(batch) * 3(embedding Dimension) * 4(X^k的field数) * 4(X^0的field数)。如果只考虑batch中第一条数据的话，应该形成的是 1 * 3 * 4 * 4的矩阵。忽略第0维，想像成一个长宽为4，高为3的长方体，长方体横向切割，第一个横截面对应的数字应该如下：</p>
<div class="image-package">
<div class="image-container" style="max-width: 700px; max-height: 478px;">
<div class="image-container-fill" style="padding-bottom: 36.27%;"></div>
<div class="image-view" data-width="1318" data-height="478"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-f4815190d2e14ffc.png" data-original-width="1318" data-original-height="478" data-original-format="image/png" data-original-filesize="51267"></div>
</div>
<div class="image-caption"></div>
</div>
<p>那么想要做到这样的结果，我们首先按输入数据的axis=2进行split：</p>
<pre><code>split_arr1 = tf.split(arr1,[1,1,1],2)
split_arr2 = tf.split(arr2,[1,1,1],2)
print(split_arr1)
print(sess.run(split_arr1))
print(sess.run(split_arr2))
</code></pre>
<p>分割后的结果如下：</p>
<div class="image-package">
<div class="image-container" style="max-width: 700px; max-height: 394px;">
<div class="image-container-fill" style="padding-bottom: 36.15%;"></div>
<div class="image-view" data-width="1090" data-height="394"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-7294179d54cd654b.png" data-original-width="1090" data-original-height="394" data-original-format="image/png" data-original-filesize="35887"></div>
</div>
<div class="image-caption"></div>
</div>
<p>通过结果我们可以看到，我们现在对每一条数据，得到了3个4 * 1的tensor，可以理解为此时的tensor大小为 3(embedding Dimension) * 2(batch) * 4(X^k 或X^0的field数) * 1。</p>
<p>此时我们进行矩阵相乘：</p>
<pre><code>res = tf.matmul(split_arr1,split_arr2,transpose_b=True)
</code></pre>
<p>这里我理解的，tensorflow对3维及以上矩阵相乘时，矩阵相乘只发生在最后两维。也就是说，3 * 2 * 4 * 1 和 3 * 2 * 1 * 4的矩阵相乘，最终的结果是3 * 2 * 4 * 4。我们来看看结果：</p>
<div class="image-package">
<div class="image-container" style="max-width: 181px; max-height: 465px;">
<div class="image-container-fill" style="padding-bottom: 256.91%;"></div>
<div class="image-view" data-width="181" data-height="465"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-4b557a605b0cc417.png" data-original-width="181" data-original-height="465" data-original-format="image/png" data-original-filesize="22345"></div>
</div>
<div class="image-caption"></div>
</div>
<p>可以看到，不仅矩阵的形状跟我们预想的一样，同时结果也跟我们预想的一样。</p>
<p>最后，我们只需要进行transpose操作，把batch转换到第0维就可以啦。</p>
<pre><code>res = tf.transpose(res,perm=[1,0,2,3])
</code></pre>
<p>这样，CIN中的第一步就大功告成了，明白了这一步如何用tensorflow实现，那么代码你也就能够顺其自然的看懂啦！</p>
<p>这一块完整的代码如下：</p>
<pre><code>import tensorflow as tf
import numpy as np

arr1 = tf.convert_to_tensor(np.arange(1,25).reshape(2,4,3),dtype=tf.int32)
arr2 = tf.convert_to_tensor(np.arange(1,25).reshape(2,4,3),dtype=tf.int32)


with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    split_arr1 = tf.split(arr1,[1,1,1],2)
    split_arr2 = tf.split(arr2,[1,1,1],2)
    print(split_arr1)
    print(sess.run(split_arr1))
    print(sess.run(split_arr2))
    res = tf.matmul(split_arr1,split_arr2,transpose_b=True)
    print(sess.run(res))
    res = tf.transpose(res,perm=[1,0,2,3])
    print(sess.run(res))
</code></pre>
<h1>4、XDeepFM的TF实现</h1>
<p>本文的代码来自github地址：<a href="https://github.com/Leavingseason/xDeepFM" target="_blank" rel="nofollow">https://github.com/Leavingseason/xDeepFM</a><br>
而我的github库中也偷偷把这里面的代码加进去啦：<a href="https://github.com/princewen/tensorflow_practice/tree/master/recommendation/Basic-XDeepFM-Demo" target="_blank" rel="nofollow">https://github.com/princewen/tensorflow_practice/tree/master/recommendation/Basic-XDeepFM-Demo</a></p>
<p>真的是写的非常好的一段代码，希望大家可以比着自己敲一敲，相信你会有所收获。</p>
<p>具体的代码细节我们不展开进行讨论，我们只说一下数据的问题吧：<br>
1、代码中的数据按照ffm的格式存储，格式如下：filed:n th dimension:value,即这个特征属于第几个field，在所有特征全部按one-hot展开后的第几维(而不是在这个field中是第几维)以及对应的特征值。<br>
2、代码中使用到的数据属于多值的离散特征。</p>
<p>关于代码实现细节，我们这里只说一下CIN的实现：</p>
<p>由于X^0 在每一层都有用到，所以我们先对 X^0 进行一个处理：</p>
<pre><code>nn_input = tf.reshape(nn_input, shape=[-1, int(field_num), hparams.dim])
split_tensor0 = tf.split(hidden_nn_layers[0], hparams.dim * [1], 2)
</code></pre>
<p>在计算X^k 时，我们需要用到 X^k-1 的数据，代码中用hidden_nn_layers保存这些数据。对X^k-1 进行和X^0 同样的处理：</p>
<pre><code>split_tensor = tf.split(hidden_nn_layers[-1], hparams.dim * [1], 2)
</code></pre>
<p>接下来就是我们之前讲过的，对两个split之后的tensor进行相乘再转置的过程啦：</p>
<pre><code>dot_result_m = tf.matmul(split_tensor0, split_tensor, transpose_b=True)
dot_result_o = tf.reshape(dot_result_m, shape=[hparams.dim, -1, field_nums[0]*field_nums[-1]])
dot_result = tf.transpose(dot_result_o, perm=[1, 0, 2])
</code></pre>
<p>接下来，我们需要进行CIN的第二步，先回顾一下：</p>
<div class="image-package">
<div class="image-container" style="max-width: 467px; max-height: 457px;">
<div class="image-container-fill" style="padding-bottom: 97.86%;"></div>
<div class="image-view" data-width="467" data-height="457"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-576be6de0a1dbeb5.png" data-original-width="467" data-original-height="457" data-original-format="image/png" data-original-filesize="89291"></div>
</div>
<div class="image-caption"></div>
</div>
<p>这里我们用1维卷积实现，假设X^K的field的数量我们起名为layer_size:</p>
<pre><code>filters = tf.get_variable(name="f_"+str(idx),
                     shape=[1, field_nums[-1]*field_nums[0], layer_size],
                     dtype=tf.float32)

curr_out = tf.nn.conv1d(dot_result, filters=filters, stride=1, padding='VALID')
</code></pre>
<p>此时我们curr_out的大小就是 Batch * Embedding Size * Layer size，我们需要进行一下转置：</p>
<pre><code>curr_out = tf.transpose(curr_out, perm=[0, 2, 1])
</code></pre>
<p>接下来就是最后一步，进行sumpooling，如下图：</p>
<div class="image-package">
<div class="image-container" style="max-width: 530px; max-height: 374px;">
<div class="image-container-fill" style="padding-bottom: 70.57%;"></div>
<div class="image-view" data-width="530" data-height="374"><img data-original-src="//upload-images.jianshu.io/upload_images/4155986-18bdea2ca62019ee.png" data-original-width="530" data-original-height="374" data-original-format="image/png" data-original-filesize="50561"></div>
</div>
<div class="image-caption"></div>
</div>
<p>代码中有两种选择方式，direct方式和非direct方式，direct方式，直接把完整curr_out作为最后输出结果的一部分，同时把完整的curr_out作为计算下一个隐藏层向量的输入。非direct方式，把curr_out按照layer_size进行均分，前一半作为计算下一个隐藏层向量的输入，后一半作为最后输出结果的一部分。</p>
<pre><code>
if direct:
    hparams.logger.info("all direct connect")
    direct_connect = curr_out
    next_hidden = curr_out
    final_len += layer_size
    field_nums.append(int(layer_size))

else:
    hparams.logger.info("split connect")
    if idx != len(hparams.cross_layer_sizes) - 1:
        next_hidden, direct_connect = tf.split(curr_out, 2 * [int(layer_size / 2)], 1)
        final_len += int(layer_size / 2)
    else:
        direct_connect = curr_out
        next_hidden = 0
        final_len += layer_size
    field_nums.append(int(layer_size / 2))

final_result.append(direct_connect)
hidden_nn_layers.append(next_hidden)
</code></pre>
<p>最后 ，经过sum_pooling操作，再拼接一个输出层，我们就得到了CIN部分的输出：</p>
<pre><code>result = tf.concat(final_result, axis=1)
result = tf.reduce_sum(result, -1)

hparams.logger.info("no residual network")
w_nn_output = tf.get_variable(name='w_nn_output',
                              shape=[final_len, 1],
                              dtype=tf.float32)
b_nn_output = tf.get_variable(name='b_nn_output',
                              shape=[1],
                              dtype=tf.float32,
                              initializer=tf.zeros_initializer())
self.layer_params.append(w_nn_output)
self.layer_params.append(b_nn_output)
exFM_out = tf.nn.xw_plus_b(result, w_nn_output, b_nn_output)
</code></pre>
<h1>5、总结</h1>
<p>我们今天介绍的xDeepFM模型，由linear、DNN、CIN三部分组成，其中CIN实现了自动学习显式的高阶特征交互，同时使得交互发生在向量级上。该模型在几个数据集上都取得了超过DeepFM模型的效果。</p>
<h1>参考文献</h1>
<p>1、论文：<a href="https://arxiv.org/abs/1803.05170" target="_blank" rel="nofollow">https://arxiv.org/abs/1803.05170</a><br>
2、特征交互：一种极深因子分解机模型（xDeepFM）：<a href="https://www.xianjichina.com/news/details_81731.html" target="_blank" rel="nofollow">https://www.xianjichina.com/news/details_81731.html</a><br>
3、<a href="https://blog.csdn.net/SangrealLilith/article/details/80272346" target="_blank" rel="nofollow">https://blog.csdn.net/SangrealLilith/article/details/80272346</a><br>
4、<a href="https://github.com/Leavingseason/xDeepFM" target="_blank" rel="nofollow">https://github.com/Leavingseason/xDeepFM</a></p>

          </div>
        </div>
    </div>

    <!-- 如果是付费文章，未购买，则显示购买按钮 -->

    <!-- 连载目录项 -->

    <!-- 如果是付费文章 -->
      <!-- 如果是付费连载，已购买，且作者允许赞赏，则显示付费信息和赞赏 -->
        <div data-vcomp="free-reward-panel"></div>

      <div class="show-foot">
        <a class="notebook" href="/nb/21403842">
          <i class="iconfont ic-search-notebook"></i>
          <span>推荐系统理论及实战</span>
</a>        <div class="copyright" data-toggle="tooltip" data-html="true" data-original-title="转载请联系作者获得授权，并标注“简书作者”。">
          © 著作权归作者所有
        </div>
        <div class="modal-wrap" data-report-note>
          <a id="report-modal">举报文章</a>
        </div>
      </div>

      <!-- 文章底部作者信息 -->
        <div class="follow-detail">
          <div class="info">
            <a class="avatar" href="/u/c5df9e229a67">
              <img src="//upload.jianshu.io/users/upload_avatars/4155986/0b79def0-fd6c-44d8-9410-1c13d3a2cf7e.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/96/h/96" alt="96" />
</a>            <div props-data-classes="user-follow-button-footer" data-author-follow-button></div>
            <a class="title" href="/u/c5df9e229a67">石晓文的学习日记</a>
              <i class="iconfont ic-man"></i>
          </div>
            <div class="signature">个人公众号：小小挖掘机，关注可获取加入交流群方式哟，目前微信群一群已满，二群坑位众多！</div>
        </div>

    <div class="meta-bottom">
      <div class="btn like-group"></div>
      <div class="share-group">
        <a class="share-circle" data-action="weixin-share" data-toggle="tooltip" data-original-title="分享到微信">
          <i class="iconfont ic-wechat"></i>
        </a>
        <a class="share-circle" data-action="weibo-share" data-toggle="tooltip" href="javascript:void((function(s,d,e,r,l,p,t,z,c){var%20f=&#39;http://v.t.sina.com.cn/share/share.php?appkey=1881139527&#39;,u=z||d.location,p=[&#39;&amp;url=&#39;,e(u),&#39;&amp;title=&#39;,e(t||d.title),&#39;&amp;source=&#39;,e(r),&#39;&amp;sourceUrl=&#39;,e(l),&#39;&amp;content=&#39;,c||&#39;gb2312&#39;,&#39;&amp;pic=&#39;,e(p||&#39;&#39;)].join(&#39;&#39;);function%20a(){if(!window.open([f,p].join(&#39;&#39;),&#39;mb&#39;,[&#39;toolbar=0,status=0,resizable=1,width=440,height=430,left=&#39;,(s.width-440)/2,&#39;,top=&#39;,(s.height-430)/2].join(&#39;&#39;)))u.href=[f,p].join(&#39;&#39;);};if(/Firefox/.test(navigator.userAgent))setTimeout(a,0);else%20a();})(screen,document,encodeURIComponent,&#39;&#39;,&#39;&#39;,&#39;&#39;, &#39;推荐 @纯良太子小文 的文章《推荐系统遇上深度学习(二十二)--DeepFM升级版XDeepFM模型强势来袭！》（ 分享自 @简书 ）&#39;,&#39;https://www.jianshu.com/p/b4128bc79df0?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=weibo&#39;,&#39;页面编码gb2312|utf-8默认gb2312&#39;));" data-original-title="分享到微博">
          <i class="iconfont ic-weibo"></i>
        </a>
        <a class="share-circle" data-toggle="tooltip"  id="longshare" target="_blank">
            <div class="qrcode" id="qrcode">
             <img src="//cdn2.jianshu.io/assets/web/download-index-side-qrcode-cb13fc9106a478795f8d10f9f632fccf.png" alt="Download index side qrcode" />
             <p>下载app生成长微博图片</p>
             </div>
          <i class="iconfont ic-picture"></i>
        </a>
        <a class="share-circle more-share" tabindex="0" data-toggle="popover" data-placement="top" data-html="true" data-trigger="focus" href="javascript:void(0);" data-content='
          <ul class="share-list">
            <li><a href="javascript:void(function(){var d=document,e=encodeURIComponent,r=&#39;http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=&#39;+e(&#39;https://www.jianshu.com/p/b4128bc79df0?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=qzone&#39;)+&#39;&amp;title=&#39;+e(&#39;推荐 石晓文的学习日记 的文章《推荐系统遇上深度学习(二十二)--DeepFM升级版XDeepFM模型强势来袭！》&#39;),x=function(){if(!window.open(r,&#39;qzone&#39;,&#39;toolbar=0,resizable=1,scrollbars=yes,status=1,width=600,height=600&#39;))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();"><i class="social-icon-sprite social-icon-zone"></i><span>分享到QQ空间</span></a></li>
            <li><a href="javascript:void(function(){var d=document,e=encodeURIComponent,r=&#39;https://twitter.com/share?url=&#39;+e(&#39;https://www.jianshu.com/p/b4128bc79df0?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=twitter&#39;)+&#39;&amp;text=&#39;+e(&#39;推荐 石晓文的学习日记 的文章《推荐系统遇上深度学习(二十二)--DeepFM升级版XDeepFM模型强势来袭！》（ 分享自 @jianshucom ）&#39;)+&#39;&amp;related=&#39;+e(&#39;jianshucom&#39;),x=function(){if(!window.open(r,&#39;twitter&#39;,&#39;toolbar=0,resizable=1,scrollbars=yes,status=1,width=600,height=600&#39;))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();"><i class="social-icon-sprite social-icon-twitter"></i><span>分享到Twitter</span></a></li>
            <li><a href="javascript:void(function(){var d=document,e=encodeURIComponent,r=&#39;https://www.facebook.com/dialog/share?app_id=483126645039390&amp;display=popup&amp;href=https://www.jianshu.com/p/b4128bc79df0?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=facebook&#39;,x=function(){if(!window.open(r,&#39;facebook&#39;,&#39;toolbar=0,resizable=1,scrollbars=yes,status=1,width=450,height=330&#39;))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();"><i class="social-icon-sprite social-icon-facebook"></i><span>分享到Facebook</span></a></li>
            <li><a href="javascript:void(function(){var d=document,e=encodeURIComponent,r=&#39;https://plus.google.com/share?url=&#39;+e(&#39;https://www.jianshu.com/p/b4128bc79df0?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=google_plus&#39;),x=function(){if(!window.open(r,&#39;google_plus&#39;,&#39;toolbar=0,resizable=1,scrollbars=yes,status=1,width=450,height=330&#39;))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();"><i class="social-icon-sprite social-icon-google"></i><span>分享到Google+</span></a></li>
            <li><a href="javascript:void(function(){var d=document,e=encodeURIComponent,s1=window.getSelection,s2=d.getSelection,s3=d.selection,s=s1?s1():s2?s2():s3?s3.createRange().text:&#39;&#39;,r=&#39;http://www.douban.com/recommend/?url=&#39;+e(&#39;https://www.jianshu.com/p/b4128bc79df0?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=douban&#39;)+&#39;&amp;title=&#39;+e(&#39;推荐系统遇上深度学习(二十二)--DeepFM升级版XDeepFM模型强势来袭！&#39;)+&#39;&amp;sel=&#39;+e(s)+&#39;&amp;v=1&#39;,x=function(){if(!window.open(r,&#39;douban&#39;,&#39;toolbar=0,resizable=1,scrollbars=yes,status=1,width=450,height=330&#39;))location.href=r+&#39;&amp;r=1&#39;};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})()"><i class="social-icon-sprite social-icon-douban"></i><span>分享到豆瓣</span></a></li>
          </ul>
        '>更多分享</a>
      </div>
    </div>

      <a id="web-note-ad-1" target="_blank" href="/apps/redirect?utm_source=note-bottom-click"><img src="//cdn2.jianshu.io/assets/web/web-note-ad-1-c2e1746859dbf03abe49248893c9bea4.png" alt="Web note ad 1" /></a>

    <!--
    <div id="note-comment-above-ad-container">
      <span id="youdao-comment-ad" class="ad-badge">广告</span>
    </div>
    -->
    <div id="vue_comment"></div>
  </div>

  <div class="vue-side-tool" props-data-props-show-qr-code="0"></div>
</div>
<div class="note-bottom">
  <div class="js-included-collections"></div>
  <div data-vcomp="recommended-notes" data-lazy="1.5" data-note-id="34140712"></div>
  <!-- 相关文章 -->
    <!-- 未登录用户 -->
    <div class="seo-recommended-notes">

          <div class="note have-img">
            <a class="cover" target="_blank" href="/p/99e8f24ec7df?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <img src="//upload-images.jianshu.io/upload_images/4155986-d0f6bd99198a0531?imageMogr2/auto-orient/strip|imageView2/1/w/300/h/240" alt="240" />
</a>            <a class="title" target="_blank" href="/p/99e8f24ec7df?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">推荐系统遇上深度学习(二十一)--阶段性回顾</a>
            <p class="description">本系列已经写了二十篇了，但推荐系统的东西还有很多值得探索和学习的地方。不过在这之前，我们先静下心来，一起回顾下之前学习到的东西！ 由于是总结性质的文章，很多细节不会过多的涉及，有兴趣的同学可以点击文章中给出的链接进行学习。 本文中涉及的大多数算法是计算广告中点击率预估用到的...</p>
            <a class="author" target="_blank" href="/u/c5df9e229a67?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <div class="avatar">
                <img src="//upload.jianshu.io/users/upload_avatars/4155986/0b79def0-fd6c-44d8-9410-1c13d3a2cf7e.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
              </div>
              <span class="name">石晓文的学习日记</span>
</a>          </div>

          <div class="note ">
                        <a class="title" target="_blank" href="/p/4a3c5e34d0f8?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">总结一点面试问题－－算法工程师（机器学习）</a>
            <p class="description">~~~~~·个人整理，如需转载，请说明并备注，不甚感激~~~~~~ csdn博客文章地址 需要内推三七互娱的盆友萌，（9月5号截止）可以参考另一篇文章，或者内推QQ群：175423207 BAT机器学习面试系列 1.请简要介绍下SVM。 SVM，全称是support vec...</p>
            <a class="author" target="_blank" href="/u/ff138b35b8ed?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <div class="avatar">
                <img src="//upload.jianshu.io/users/upload_avatars/4419703/0156fda7-7cce-4a99-ae3c-c7277873551f?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
              </div>
              <span class="name">suxuer</span>
</a>          </div>

          <div class="note have-img">
            <a class="cover" target="_blank" href="/p/fdd348db23fe?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <img src="//upload-images.jianshu.io/upload_images/11550176-ca6fbd5278168c6b.png?imageMogr2/auto-orient/strip|imageView2/1/w/300/h/240" alt="240" />
</a>            <a class="title" target="_blank" href="/p/fdd348db23fe?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">深度学习综述</a>
            <p class="description">The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches 作者：Md Zahangir Alom, Tarek M. Taha, Christopher Yakopc...</p>
            <a class="author" target="_blank" href="/u/ec6093f99ec0?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <div class="avatar">
                <img src="//upload.jianshu.io/users/upload_avatars/11550176/9dee9a76-8633-4e17-90a2-5f938c739358.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
              </div>
              <span class="name">Limityoung</span>
</a>          </div>

          <div class="note ">
                        <a class="title" target="_blank" href="/p/bf597ef95777?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">大数据算法</a>
            <p class="description">栈 1. 栈（stack）又名堆栈，它是一种运算受限的线性表。其限制是仅允许在表的一端进行插入和删除运算。这一端被称为栈顶，相对地，把另一端称为栈底。向一个栈插入新元素又称作进栈、入栈或压栈，它是把新元素放到栈顶元素的上面，使之成为新的栈顶元素；从一个栈删除元素又称作出栈或...</p>
            <a class="author" target="_blank" href="/u/5fb8704ba819?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <div class="avatar">
                <img src="//upload.jianshu.io/users/upload_avatars/11543726/3a86fd18-d773-435b-bda9-15844925fc34.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
              </div>
              <span class="name">IT程序员</span>
</a>          </div>

          <div class="note ">
                        <a class="title" target="_blank" href="/p/d593dbb87ffe?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">深度学习综述</a>
            <p class="description">文章主要分为：一、深度学习概念；二、国内外研究现状；三、深度学习模型结构；四、深度学习训练算法；五、深度学习的优点；六、深度学习已有的应用；七、深度学习存在的问题及未来研究方向；八、深度学习开源软件。 一、深度学习概念 深度学习(Deep Learning, DL)由Hin...</p>
            <a class="author" target="_blank" href="/u/963bb09806b3?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <div class="avatar">
                <img src="//upload.jianshu.io/users/upload_avatars/4217675/02da9f8d-d17e-428c-a11b-6cb0f02b809a.png?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
              </div>
              <span class="name">MoreThanA_coder</span>
</a>          </div>

          <div class="note ">
                        <a class="title" target="_blank" href="/p/8af97fdd2a64?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">忆恩师</a>
            <p class="description">    说出来惭愧，我没上过高中和大学，这使我的人生似乎也缺失了一些精彩，多了一些遗憾。我是从初中直接考了一所师范学校。尽管如此教过我的老师也多多少少有三十几人，而我的这些老师中给我影响最深的是我初中的班主任兼语文老师魏老师。魏老师高高的个子，长方形的脸，说起话来慢条斯理的...</p>
            <a class="author" target="_blank" href="/u/51101931615e?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <div class="avatar">
                <img src="//upload.jianshu.io/users/upload_avatars/7618952/f869974b-2b24-4820-8cbc-cd57e3db20a3.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
              </div>
              <span class="name">芳华醉春风</span>
</a>          </div>

          <div class="note ">
                        <a class="title" target="_blank" href="/p/81e27b762767?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">2017-10-25</a>
            <p class="description">今天中午放学后，妈妈带我去接送站吃饭，我们吃饱了饭，就想回家了，可是妈妈没开车来，我们得坐803路公交车回家，妈妈不知道803路站牌儿在哪儿，我们就去问交警叔叔，交警叔叔告诉我们站牌儿在新星家具的门口。我们就去了那，我们看到了一个卖烧饼的，在接送站我吃的饭不多妈妈就给我买了...</p>
            <a class="author" target="_blank" href="/u/0acf5b0d1b8b?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <div class="avatar">
                <img src="//cdn2.jianshu.io/assets/default_avatar/6-fd30f34c8641f6f32f5494df5d6b8f3c.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
              </div>
              <span class="name">静如思</span>
</a>          </div>

          <div class="note ">
                        <a class="title" target="_blank" href="/p/02df08d66553?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">教知识，育心灵</a>
            <p class="description">从事教育工作这么多年以来，我发现很多父母在家庭教育方面存在畸形的思想。在各级的升学考试中，分数成了父母衡量孩子是好是坏的唯一标准。家长几乎把所有的注意力都集中在孩子的考试分数上，一味地要求孩子努力学习，与此同时，却严重忽视了孩子的心灵成长和心理发展。 孩子在成长的过程中，既...</p>
            <a class="author" target="_blank" href="/u/198578319cdc?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <div class="avatar">
                <img src="//upload.jianshu.io/users/upload_avatars/6494046/f7d65cbb-d0c1-4c29-a005-b056591c1548?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
              </div>
              <span class="name">吴悦溪</span>
</a>          </div>

          <div class="note have-img">
            <a class="cover" target="_blank" href="/p/ad2c90702be8?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <img src="//upload-images.jianshu.io/upload_images/2953327-2a6de7a3638b37f7.png?imageMogr2/auto-orient/strip|imageView2/1/w/300/h/240" alt="240" />
</a>            <a class="title" target="_blank" href="/p/ad2c90702be8?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">范冰冰被迫离场的真相，谁的过错？</a>
            <p class="description">如今随着电影行业的发展，越来越多的电影选择在一些影响力比较大的学校与媒体和学生见面。近日，电影《我不是潘金莲》的导演冯小刚、编剧刘震云以及主演范冰冰，来到武汉，华中师范大学参加“喜剧的挑战”研讨会。 在主演范冰冰到场仅有十分钟后，校方便要求范冰冰立刻离场导致冯小刚导演对本次...</p>
            <a class="author" target="_blank" href="/u/ae2698c56b68?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <div class="avatar">
                <img src="//upload.jianshu.io/users/upload_avatars/2953327/55bef7f1ed9b?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
              </div>
              <span class="name">视佳文化传媒</span>
</a>          </div>

          <div class="note have-img">
            <a class="cover" target="_blank" href="/p/e1549e3c30aa?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <img src="//upload-images.jianshu.io/upload_images/1731398-2a72ce8136f7bde2.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/300/h/240" alt="240" />
</a>            <a class="title" target="_blank" href="/p/e1549e3c30aa?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">防放弃写作的指导</a>
            <p class="description">【引子】 我是胖z,这是我决定开始写作并且真正动笔的第一天。设想如果我能一直坚持写下去，写作或许就能成为我的一个符号，那么这开始的第一天是我决定给自己的生命增加点新鲜颜色的开端，是个值得纪念的日子，我得写点儿什么给这样的日子添点儿亮度。 不过，设想通常都很美好，仿佛自己完成...</p>
            <a class="author" target="_blank" href="/u/42edf9728e1d?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
              <div class="avatar">
                <img src="//cdn2.jianshu.io/assets/default_avatar/14-0651acff782e7a18653d7530d6b27661.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
              </div>
              <span class="name">胖z</span>
</a>          </div>
    </div>
</div>

    <script type="application/json" data-name="page-data">{"user_signed_in":false,"locale":"zh-CN","os":"mac","read_mode":"day","read_font":"font2","note_show":{"is_author":false,"is_following_author":false,"is_liked_note":false,"follow_state":0,"uuid":"41c14604-3041-4a70-bdf3-2b3d240dfa4b"},"note":{"id":34140712,"slug":"b4128bc79df0","user_id":4155986,"notebook_id":21403842,"commentable":true,"likes_count":12,"views_count":2713,"public_wordage":3733,"comments_count":0,"featured_comments_count":0,"total_rewards_count":0,"is_author":false,"paid_type":"free","paid":false,"paid_content_accessible":false,"author":{"nickname":"石晓文的学习日记","total_wordage":534463,"followers_count":3586,"total_likes_count":2669}}}</script>
    
    <script src="//cdn2.jianshu.io/assets/babel-polyfill-6cd2d6b53fe3184b71cc.js" crossorigin="anonymous"></script>
    <script src="//cdn2.jianshu.io/assets/web-base-3884f64e8dd7fdf0a8f0.js" crossorigin="anonymous"></script>
<script src="//cdn2.jianshu.io/assets/web-05daee6d4d872449f8f4.js" crossorigin="anonymous"></script>
    
    <script src="//cdn2.jianshu.io/assets/web/pages/notes/show/entry-82e44627b2e2d73431d6.js" crossorigin="anonymous"></script>
    <script>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
</script>

  </body>
</html>
