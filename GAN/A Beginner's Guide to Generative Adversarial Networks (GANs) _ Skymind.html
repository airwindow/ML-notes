<!DOCTYPE html>
<!-- saved from url=(0058)https://skymind.ai/wiki/generative-adversarial-network-gan -->
<html data-wf-site="5734be9dc497153609d0cf28" data-wf-page="573b6bf09e2dc7c46dee6fc4" class=" w-mod-js w-mod-no-touch w-mod-video w-mod-no-ios" style=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>
    
      A Beginner's Guide to Generative Adversarial Networks (GANs) | Skymind
    
  </title>
<meta content="Skymind" property="og:site_name">
<meta content="A Beginner&#39;s Guide to Generative Adversarial Networks (GANs)" property="og:title">
<meta content="article" property="og:type">
<meta content="Generative adversarial networks (GANs) are deep neural net architectures comprised of two nets, pitting one against the other." property="og:description">
<meta name="description" content="Generative adversarial networks (GANs) are deep neural net architectures comprised of two nets, pitting one against the other.">
<meta content="http://skymind.ai/wiki/generative-adversarial-network-gan" property="og:url">
<meta name="twitter:card" content="summary">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="shortcut icon" type="image/x-icon" href="https://skymind.ai/images/favicon.png">
<link rel="stylesheet" type="text/css" href="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/normalize.css">
<link rel="stylesheet" type="text/css" href="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/components.css">
<link rel="stylesheet" type="text/css" href="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/skymind.css">
<link rel="stylesheet" href="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/font-awesome.min.css">

<style>.async-hide { opacity: 0 !important} </style>
<script type="text/javascript" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/pd.js"></script><script src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/conversations-embed.js" type="text/javascript" id="hubspot-messages-loader" data-loader="hs-scriptloader" data-hsjs-portal="2179705" data-hsjs-env="prod"></script><script src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/2179705.js" type="text/javascript" id="hs-analytics"></script><script type="text/javascript" async="" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/5605.js"></script><script type="text/javascript" async="" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/analytics.js"></script><script type="text/javascript" async="" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/js"></script><script async="" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/gtm.js"></script><script async="" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/analytics.js"></script><script>(function(a,s,y,n,c,h,i,d,e){s.className+=' '+y;h.start=1*new Date;
  h.end=i=function(){s.className=s.className.replace(RegExp(' ?'+y),'')};
  (a[n]=a[n]||[]).hide=h;setTimeout(function(){i();h.end=null},c);h.timeout=c;
  })(window,document.documentElement,'async-hide','dataLayer',4000,
  {'GTM-T2DSBKT':true});</script>
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-48811288-3', 'auto');
    ga('require', 'GTM-T2DSBKT');
    ga('send', 'pageview');
  </script>

<script type="text/javascript" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/modernizr.js"></script>
<link rel="apple-touch-icon" href="https://skymind.ai/images/webclip.png">
<script src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/jquery-3.2.1.js" integrity="sha256-DZAnKJ/6XZ9si04Hgrsxu/8s717jcIzLy3oi35EouyE=" crossorigin="anonymous"></script>

<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-P824SK"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-P824SK');</script>

<script type="text/javascript" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/analytics(2)"></script></head>
<body><style type="text/css">html.hs-messages-widget-open.hs-messages-mobile,html.hs-messages-widget-open.hs-messages-mobile body{height:100%!important;overflow:hidden!important;position:relative!important}html.hs-messages-widget-open.hs-messages-mobile body{margin:0!important}#hubspot-messages-iframe-container{display:initial!important;z-index:2147483647;position:fixed!important;bottom:0!important;right:0!important}#hubspot-messages-iframe-container.internal{z-index:1016}#hubspot-messages-iframe-container.internal iframe{min-width:108px}#hubspot-messages-iframe-container .shadow{display:initial!important;z-index:-1;position:absolute;width:0;height:0;bottom:0;right:0;content:""}#hubspot-messages-iframe-container .shadow.internal{display:none!important}#hubspot-messages-iframe-container .shadow.active{width:400px;height:400px;background:radial-gradient(ellipse at bottom right,rgba(29,39,54,.16) 0,rgba(29,39,54,0) 72%)}#hubspot-messages-iframe-container iframe{display:initial!important;width:100%!important;height:100%!important;border:none!important;position:absolute!important;bottom:0!important;right:0!important;background:transparent!important}</style>

<div class="w-section hero-wiki">
<div data-collapse="small" data-animation="default" data-duration="400" data-contain="1" class="w-nav navbar-container">
<div class="w-container navbar-container"><a href="https://skymind.ai/contact" class="w-button navbar-contact--cta">CONTACT US</a>
<a href="https://skymind.ai/" class="w-nav-brand navbar-logo"><img src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/logo_skymind_white.svg" class="img-logo">
</a>
<nav class="w-nav-menu navbar-menu" role="navigation">

<a class="w-nav-link navbar-link" href="https://skymind.ai/platform" style="max-width: 940px;">AI Platform</a>

<div class="w-dropdown" data-delay="0" style="max-width: 940px;">
<div class="w-dropdown-toggle navbar-dropdown">
<div class="navbar-link">Why Skymind?</div>
</div>
<nav class="w-dropdown-list">
<a class="w-dropdown-link" href="https://skymind.ai/audience/datascientist">Data Scientists</a>
<a class="w-dropdown-link" href="https://skymind.ai/audience/architect">Solution Architects</a>
<a class="w-dropdown-link" href="https://skymind.ai/audience/devops">DevOps and SRE</a>
<a class="w-dropdown-link" href="https://skymind.ai/audience/executives">Innovation Leaders</a>
</nav>
</div>

<a class="w-nav-link navbar-link" href="https://skymind.ai/solutions" style="max-width: 940px;">Solutions</a>

<div class="w-dropdown" data-delay="0" style="max-width: 940px;">
<div class="w-dropdown-toggle navbar-dropdown">
<div class="navbar-link">Case Studies</div>
</div>
<nav class="w-dropdown-list">
<a class="w-dropdown-link" href="https://skymind.ai/case-studies/rpa">RPA</a>
<a class="w-dropdown-link" href="https://skymind.ai/case-studies/orange">Telecom Fraud</a>
<a class="w-dropdown-link" href="https://skymind.ai/case-studies/insurance">Insurance</a>
<a class="w-dropdown-link" href="https://skymind.ai/case-studies/logistics">Supply Chain &amp; Logistics</a>
<a class="w-dropdown-link" href="https://skymind.ai/case-studies/canonical">Cybersecurity and Data Centers</a>
<a class="w-dropdown-link" href="https://skymind.ai/case-studies/finance">Financial Services</a>
<a class="w-dropdown-link" href="https://skymind.ai/case-studies/image">Image Recognition</a>
<a class="w-dropdown-link" href="https://skymind.ai/case-studies/commerce">Commerce and CRM</a>
</nav>
</div>

<a class="w-nav-link navbar-link" href="https://www.skymind.ai/about" style="max-width: 940px;">About</a>

<div class="w-dropdown" data-delay="0" style="max-width: 940px;">
<div class="w-dropdown-toggle navbar-dropdown">
<div class="navbar-link">Resources</div>
</div>
<nav class="w-dropdown-list">
<a class="w-dropdown-link" href="https://skymind.ai/subscription">Subscription</a>
<a class="w-dropdown-link" href="https://docs.skymind.ai/docs" target="_blank">Documentation</a>
<a class="w-dropdown-link" href="https://github.com/SkymindIO/SKIL-CE/issues" target="_blank">Community Support</a>
<a class="w-dropdown-link" href="https://blog.skymind.ai/" target="_blank">Blog</a>
<a class="w-dropdown-link" href="https://skymind.ai/wiki/">AI Wiki</a>
<a class="w-dropdown-link" href="https://skymind.ai/open-source.html">Open-Source</a>
</nav>
</div>
</nav>
<div class="w-nav-button menu-hamburger">
<div class="w-icon-nav-menu icon-hamburger"></div>
</div>
</div>
<div class="w-nav-overlay" data-wf-ignore=""></div></div>
<div class="w-container">
<div class="hero-sub-div">
<h1 class="hero-h1-small">A.I. Wiki</h1>
</div>
</div>
</div>
<div class="w-section section-cta">
<div class="w-container container-newsletter">
<div class="w-row">
<div class="w-col w-col-7" style="margin-top: 22px">
<p class="body-h3-cta">Do you like this content? We'll send you more.</p>
</div>
<div class="w-col w-col-5" style="margin-top: 13px">
<div class="w-form">
<iframe src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/jsv68v.html" width="100%" height="40px" type="text/html" frameborder="0" allowtransparency="true" style="border: 0"></iframe>
</div>
</div>
</div>
</div>
</div>
<div class="w-section section-white">
<div class="container-white w-wiki-container">
<div class="w-row">
<div class="w-col w-col-4 wiki-nav">

<input type="checkbox" id="wiki-toggle">
<label for="wiki-toggle">
<span class="w-icon-nav-menu icon-hamburger"></span>
Directory
</label>

<div class="collapseable">
<div class="wiki-home">
<a href="https://skymind.ai/wiki/">Artificial Intelligence Wiki</a>
</div>
<div class="wiki-search">
<input id="wiki-search-input" class="wiki-search-input" type="text" placeholder="Search articles..." onkeyup="wikiSearchFn()">
</div>
<div class="wiki-links">
<ul id="wiki-links-ul">
<li><a href="https://skymind.ai/wiki/accuracy-precision-recall-f1"></a></li>
<li><a href="https://skymind.ai/wiki/active-learning">Active Learning</a></li>
<li><a href="https://skymind.ai/wiki/ai-infrastructure-machine-learning-operations-mlops"></a></li>
<li><a href="https://skymind.ai/wiki/ai-vs-machine-learning-vs-deep-learning">AI vs. ML vs. DL</a></li>
<li><a href="https://skymind.ai/wiki/ai-winter"></a></li>
<li><a href="https://skymind.ai/wiki/apache-spark-deep-learning">Apache Spark</a></li>
<li><a href="https://skymind.ai/wiki/arbiter">Arbiter</a></li>
<li><a href="https://skymind.ai/wiki/artificial-intelligence-ai">Artificial Intelligence (AI)</a></li>
<li><a href="https://skymind.ai/wiki/attention-mechanism-memory-network">Attention Mechanisms &amp; Memory Networks</a></li>
<li><a href="https://skymind.ai/wiki/automl-automated-machine-learning-ai">Automated Machine Learning &amp; AI</a></li>
<li><a href="https://skymind.ai/wiki/autonomous-vehicle">Autonomous Vehicle</a></li>
<li><a href="https://skymind.ai/wiki/backpropagation">Backpropagation</a></li>
<li><a href="https://skymind.ai/wiki/bagofwords-tf-idf">Bag of Words &amp; TF-IDF</a></li>
<li><a href="https://skymind.ai/wiki/comparison-frameworks-dl4j-tensorflow-pytorch">Comparison of AI Frameworks</a></li>
<li><a href="https://skymind.ai/wiki/convolutional-network">Convolutional Neural Network (CNN)</a></li>
<li><a href="https://skymind.ai/wiki/data-for-deep-learning">Data for Deep Learning</a></li>
<li><a href="https://skymind.ai/wiki/datasets-ml">Datasets and Machine Learning</a></li>
<li><a href="https://skymind.ai/wiki/datavec"></a></li>
<li><a href="https://skymind.ai/wiki/decision-tree">Decision Tree</a></li>
<li><a href="https://skymind.ai/wiki/deep-autoencoder">Deep Autoencoders</a></li>
<li><a href="https://skymind.ai/wiki/deep-belief-network">Deep-Belief Networks</a></li>
<li><a href="https://skymind.ai/wiki/deep-reinforcement-learning">Deep Reinforcement Learning</a></li>
<li><a href="https://skymind.ai/wiki/deeplearning-research-papers">Deep Learning Resources</a></li>
<li><a href="https://skymind.ai/wiki/deeplearning4j">Deeplearning4j</a></li>
<li><a href="https://skymind.ai/wiki/denoising-autoencoder">Denoising Autoencoders</a></li>
<li><a href="https://skymind.ai/wiki/devops-machine-learning">Machine Learning DevOps</a></li>
<li><a href="https://skymind.ai/wiki/differentiableprogramming">Differentiable Programming</a></li>
<li><a href="https://skymind.ai/wiki/eigenvector">Eigenvectors, Eigenvalues, PCA, Covariance and Entropy</a></li>

<li><a href="https://skymind.ai/wiki/evolutionary-genetic-algorithm">Evolutionary &amp; Genetic Algorithms</a></li>
<li><a href="https://skymind.ai/wiki/fraud-detection">Fraud and Anomaly Detection</a></li>
<li><a href="https://skymind.ai/wiki/generative-adversarial-network-gan" class="w--current">Generative Adversarial Network (GAN)</a></li>
<li><a href="https://skymind.ai/wiki/glossary">Glossary</a></li>
<li><a href="https://skymind.ai/wiki/gluon">Gluon</a></li>
<li><a href="https://skymind.ai/wiki/graph-analysis">Graph Analytics</a></li>
<li><a href="https://skymind.ai/wiki/hopfieldnetworks">Hopfield Networks</a></li>
<li><a href="https://skymind.ai/wiki/hyperparameter">Hyperparameter</a></li>
<li><a href="https://skymind.ai/wiki/index">Wiki Home</a></li>
<li><a href="https://skymind.ai/wiki/java-ai">Java AI</a></li>
<li><a href="https://skymind.ai/wiki/jumpy">Jumpy</a></li>
<li><a href="https://skymind.ai/wiki/logistic-regression">Logistic Regression</a></li>
<li><a href="https://skymind.ai/wiki/lstm">LSTM</a></li>
<li><a href="https://skymind.ai/wiki/machine-learning-algorithms">Machine Learning Algorithms</a></li>
<li><a href="https://skymind.ai/wiki/machine-learning-demos">Machine Learning Demos</a></li>
<li><a href="https://skymind.ai/wiki/machine-learning-library-software">Machine Learning Software</a></li>
<li><a href="https://skymind.ai/wiki/machine-learning-operations-mlops">Machine Learning Operations (MLOps)</a></li>
<li><a href="https://skymind.ai/wiki/machine-learning-research-groups-labs">Machine Learning Research Groups &amp; Labs</a></li>
<li><a href="https://skymind.ai/wiki/machine-learning-workflow">Machine Learning Workflows</a></li>
<li><a href="https://skymind.ai/wiki/machine-learning">Machine Learning</a></li>
<li><a href="https://skymind.ai/wiki/markov-chain-monte-carlo">Markov Chain Monte Carlo</a></li>
<li><a href="https://skymind.ai/wiki/multilayer-perceptron">Multilayer Perceptron</a></li>
<li><a href="https://skymind.ai/wiki/natural-language-processing-nlp">Natural Language Processing (NLP)</a></li>
<li><a href="https://skymind.ai/wiki/nd4j">ND4J</a></li>
<li><a href="https://skymind.ai/wiki/neural-network-tuning">Neural Network Tuning</a></li>
<li><a href="https://skymind.ai/wiki/neural-network">Neural Network</a></li>
<li><a href="https://skymind.ai/wiki/open-datasets">Open Datasets</a></li>
<li><a href="https://skymind.ai/wiki/questions-when-applying-deep-learning">Questions When Applying Deep Learning</a></li>
<li><a href="https://skymind.ai/wiki/radial-basis-function-network-rbf">Radial Basis Function Networks</a></li>
<li><a href="https://skymind.ai/wiki/random-forest">Random Forest</a></li>
<li><a href="https://skymind.ai/wiki/recurrent-network-rnn">Recurrent Network (RNN)</a></li>
<li><a href="https://skymind.ai/wiki/recursive-neural-tensor-network">Recursive Neural Tensor Network</a></li>
<li><a href="https://skymind.ai/wiki/restricted-boltzmann-machine">Restricted Boltzmann Machine (RBM)</a></li>
<li><a href="https://skymind.ai/wiki/robotic-process-automation-rpa">Robotic Process Automation (RPA) &amp; AI</a></li>
<li><a href="https://skymind.ai/wiki/scala-ai">Scala AI</a></li>
<li><a href="https://skymind.ai/wiki/single-layer-network">Single-layer Network</a></li>
<li><a href="https://skymind.ai/wiki/skynet">Skynet</a></li>
<li><a href="https://skymind.ai/wiki/spiking-neural-network-snn">Spiking Neural Networks</a></li>
<li><a href="https://skymind.ai/wiki/stacked-denoising-autoencoder">Stacked Denoising Autoencoder (SDA)</a></li>
<li><a href="https://skymind.ai/wiki/strong-ai-general-ai">Strong AI &amp; General AI</a></li>
<li><a href="https://skymind.ai/wiki/supervised-learning">Supervised Learning</a></li>
<li><a href="https://skymind.ai/wiki/symbolic-reasoning">Symbolic Reasoning</a></li>
<li><a href="https://skymind.ai/wiki/text-analysis">Text Analysis</a></li>
<li><a href="https://skymind.ai/wiki/thought-vectors">Thought Vectors</a></li>
<li><a href="https://skymind.ai/wiki/unsupervised-learning">Unsupervised Learning</a></li>
<li><a href="https://skymind.ai/wiki/use-cases">Deep Learning Use Cases</a></li>
<li><a href="https://skymind.ai/wiki/variational-autoencoder">Variational Autoencoder (VAE)</a></li>
<li><a href="https://skymind.ai/wiki/word2vec">Word2Vec, Doc2Vec and Neural Word Embeddings</a></li>

</ul>
</div>
</div>
</div>
<div class="w-col w-col-8 wiki-content">
<img width="42" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/hr_white.png" class="hr-left">
<h1 class="wiki-title">A Beginner's Guide to Generative Adversarial Networks (GANs)</h1>
<p><em>You might not think that programmers are artists, but programming is an extremely creative profession. It’s logic-based creativity. - John Romero</em></p>
<p>Generative adversarial networks (GANs) are deep neural net architectures comprised of two nets, pitting one against the other (thus the “adversarial”).</p>
<p><a href="https://arxiv.org/abs/1406.2661" target="_blank">GANs were introduced in a paper</a> by Ian Goodfellow and other researchers at the University of Montreal, including Yoshua Bengio, in 2014. Referring to GANs, Facebook’s AI research director Yann LeCun <a href="https://www.quora.com/What-are-some-recent-and-potentially-upcoming-breakthroughs-in-deep-learning" target="_blank">called adversarial training</a> “the most interesting idea in the last 10 years in ML.”</p>
<p>GANs’ potential is huge, because they can learn to mimic any distribution of data. That is, GANs can be taught to create worlds eerily similar to our own in any domain: images, music, speech, prose. They are robot artists in a sense, and their <a href="https://www.nytimes.com/2017/08/14/arts/design/google-how-ai-creates-new-music-and-new-artists-project-magenta.html" target="_blank">output is impressive</a> – poignant even.</p>
<p>In a surreal turn, <a href="https://www.theverge.com/2018/10/23/18013190/ai-art-portrait-auction-christies-belamy-obvious-robbie-barrat-gans">Christie’s sold a portrait</a> for $432,000 that had been generated by a GAN, based on <a href="https://github.com/robbiebarrat/art-DCGAN">open-source code written by Robbie Barrat of Stanford</a>. Like most true artists, he didn’t see any of the money, which instead went to the French company, Obvious.</p>
<p><img src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/aipainter.jpg" alt="AI painter"></p>
<h2 id="generative-vs-discriminative-algorithms">Generative vs. Discriminative Algorithms</h2>
<p>To understand GANs, you should know how generative algorithms work, and for that, contrasting them with discriminative algorithms is instructive. Discriminative algorithms try to classify input data; that is, given the features of a data instance, they predict a label or category to which that data belongs.</p>
<p>For example, given all the words in an email, a discriminative algorithm could predict whether the message is <code class="highlighter-rouge">spam</code> or <code class="highlighter-rouge">not_spam</code>. <code class="highlighter-rouge">spam</code> is one of the labels, and the bag of words gathered from the email are the features that constitute the input data. When this problem is expressed mathematically, the label is called <code class="highlighter-rouge">y</code> and the features are called <code class="highlighter-rouge">x</code>. The formulation <code class="highlighter-rouge">p(y|x)</code> is used to mean “the probability of y given x”, which in this case would translate to “the probability that an email is spam given the words it contains.”</p>
<p>So discriminative algorithms map features to labels. They are concerned solely with that correlation. One way to think about generative algorithms is that they do the opposite. Instead of predicting a label given certain features, they attempt to predict features given a certain label.</p>
<p>The question a generative algorithm tries to answer is: Assuming this email is spam, how likely are these features? While discriminative models care about the relation between <code class="highlighter-rouge">y</code> and <code class="highlighter-rouge">x</code>, generative models care about “how you get x.” They allow you to capture <code class="highlighter-rouge">p(x|y)</code>, the probability of <code class="highlighter-rouge">x</code> given <code class="highlighter-rouge">y</code>, or the probability of features given a class. (That said, generative algorithms can also be used as classifiers. It just so happens that they can do more than categorize input data.)</p>
<p>Another way to think about it is to distinguish discriminative from generative like this:</p>
<ul>
<li>Discriminative models learn the boundary between classes</li>
<li>Generative models model the distribution of individual classes</li>
</ul>
<p><a class="w-button button-skilcta" href="https://nbviewer.jupyter.org/github/SkymindIO/skil-python/blob/master/examples/keras-skil-example.ipynb" style="width:75%; margin-top: 15px;" target="_blank">Getting Started with SKIL from Python</a></p>
<h2 id="how-gans-work">How GANs Work</h2>
<p>One neural network, called the <em>generator</em>, generates new data instances, while the other, the <em>discriminator</em>, evaluates them for authenticity; i.e. the discriminator decides whether each instance of data it reviews belongs to the actual training dataset or not.</p>
<p>Let’s say we’re trying to do something more banal than mimic the Mona Lisa. We’re going to generate hand-written numerals like those found in the MNIST dataset, which is taken from the real world. The goal of the discriminator, when shown an instance from the true MNIST dataset, is to recognize them as authentic.</p>
<p>Meanwhile, the generator is creating new images that it passes to the discriminator. It does so in the hopes that they, too, will be deemed authentic, even though they are fake. The goal of the generator is to generate passable hand-written digits, to lie without being caught. The goal of the discriminator is to identify images coming from the generator as fake.</p>
<p>Here are the steps a GAN takes:</p>
<ul>
<li>The generator takes in random numbers and returns an image.</li>
<li>This generated image is fed into the discriminator alongside a stream of images taken from the actual dataset.</li>
<li>The discriminator takes in both real and fake images and returns probabilities, a number between 0 and 1, with 1 representing a prediction of authenticity and 0 representing fake.</li>
</ul>
<p>So you have a double feedback loop:</p>
<ul>
<li>The discriminator is in a feedback loop with the ground truth of the images, which we know.</li>
<li>The generator is in a feedback loop with the discriminator.</li>
</ul>
<p><img src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/gan_schema.png" alt="GAN schema">
Credit: O’Reilly</p>
<p>You can think of a GAN as the combination of a counterfeiter and a cop in a game of cat and mouse, where the counterfeiter is learning to pass false notes, and the cop is learning to detect them. Both are dynamic; i.e. the cop is in training, too (maybe the central bank is flagging bills that slipped through), and each side comes to learn the other’s methods in a constant escalation.</p>
<p>The discriminator network is a standard convolutional network that can categorize the images fed to it, a binomial classifier labeling images as real or fake. The generator is an inverse convolutional network, in a sense: While a standard convolutional classifier takes an image and downsamples it to produce a probability, the generator takes a vector of random noise and upsamples it to an image. The first throws away data through downsampling techniques like maxpooling, and the second generates new data.</p>
<p>Both nets are trying to optimize a different and opposing objective function, or loss function, in a zero-zum game. This is essentially an <a href="https://arxiv.org/abs/1610.01945" target="_blank">actor-critic model</a>. As the discriminator changes its behavior, so does the generator, and vice versa. Their losses push against each other.</p>
<p><img src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/GANs.png" alt="GANs"></p>
<p>If you want to learn more about generating images, Brandon Amos wrote a great post about <a href="http://bamos.github.io/2016/08/09/deep-completion/#step-1-interpreting-images-as-samples-from-a-probability-distribution" target="_blank">interpreting images as samples from a probability distribution</a>.</p>
<h2 id="gans-autoencoders-and-vaes">GANs, Autoencoders and VAEs</h2>
<p>It may be useful to compare generative adversarial networks to other neural networks, such as autoencoders and variational autoencoders.</p>
<p>Autoencoders <em>encode</em> input data as vectors. They create a hidden, or compressed, representation of the raw data. They are useful in dimensionality reduction; that is, the vector serving as a hidden representation compresses the raw data into a smaller number of salient dimensions. Autoencoders can be paired with a so-called decoder, which allows you to reconstruct input data based on its hidden representation, much as you would with a <a href="https://skymind.ai/wiki/restricted-boltzmann-machine">restricted Boltzmann machine</a>.</p>
<p><img src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/autoencoder_schema.jpg" alt="autencoder schema">
<a href="https://blog.keras.io/building-autoencoders-in-keras.html" target="_blank">Credit: Keras blog</a></p>
<p>Variational autoencoders are generative algorithm that add an additional constraint to encoding the input data, namely that the hidden representations are normalized. Variational autoencoders are capable of both compressing data like an autoencoder and synthesizing data like a GAN. However, while GANs generate data in fine, granular detail, images generated by VAEs tend to be more blurred. Deeplearning4j’s examples include both <a href="https://github.com/deeplearning4j/dl4j-examples/tree/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/unsupervised" target="_blank">autoencoders and variational autoencoders</a>.</p>
<p>You can bucket generative algorithms into one of three types:</p>
<ul>
<li>Given a label, they predict the associated features (Naive Bayes)</li>
<li>Given a hidden representation, they predict the associated features (VAE, GAN)</li>
<li>Given some of the features, they predict the rest (inpainting, imputation)</li>
</ul>
<h2 id="tips-in-training-a-gan">Tips in Training a GAN</h2>
<p>When you train the discriminator, hold the generator values constant; and when you train the generator, hold the discriminator constant. Each should train against a static adversary. For example, this gives the generator a better read on the gradient it must learn by.</p>
<p>By the same token, pretraining the discriminator against MNIST before you start training the generator will establish a clearer gradient.</p>
<p>Each side of the GAN can overpower the other. If the discriminator is too good, it will return values so close to 0 or 1 that the generator will struggle to read the gradient. If the generator is too good, it will persistently exploit weaknesses in the discriminator that lead to false negatives. This may be mitigated by the nets’ respective learning rates.</p>
<p>GANs take a long time to train. On a single GPU a GAN might take hours, and on a single CPU more than a day. While difficult to tune and therefore to use, GANs have stimulated a lot of <a href="https://blog.openai.com/generative-models/" target="_blank">interesting research and writing</a>.</p>
<h2 id="just-show-me-the-code">Just Show Me the Code</h2>
<p>Here’s an example of a <a href="https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py" target="_blank">GAN coded in Keras</a>, from which models can be imported to Deeplearning4j.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">class</span> <span class="n">GAN</span><span class="p">():</span>
    <span class="n">def</span> <span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">img_rows</span> <span class="p">=</span> <span class="m">28</span>
        <span class="n">self</span><span class="p">.</span><span class="n">img_cols</span> <span class="p">=</span> <span class="m">28</span>
        <span class="n">self</span><span class="p">.</span><span class="n">channels</span> <span class="p">=</span> <span class="m">1</span>
        <span class="n">self</span><span class="p">.</span><span class="n">img_shape</span> <span class="p">=</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">img_rows</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">img_cols</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">channels</span><span class="p">)</span>

        <span class="n">optimizer</span> <span class="p">=</span> <span class="n">Adam</span><span class="p">(</span><span class="m">0.0002</span><span class="p">,</span> <span class="m">0.5</span><span class="p">)</span>

        <span class="p">#</span> <span class="n">Build</span> <span class="k">and</span> <span class="nf">compile</span> <span class="n">the</span> <span class="n">discriminator</span>
        <span class="n">self</span><span class="p">.</span><span class="n">discriminator</span> <span class="p">=</span> <span class="n">self</span><span class="p">.</span><span class="n">build_discriminator</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="p">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="p">=</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">metrics</span><span class="p">=[</span><span class="s1">'accuracy'</span><span class="p">])</span>

        <span class="p">#</span> <span class="n">Build</span> <span class="k">and</span> <span class="nf">compile</span> <span class="n">the</span> <span class="n">generator</span>
        <span class="n">self</span><span class="p">.</span><span class="n">generator</span> <span class="p">=</span> <span class="n">self</span><span class="p">.</span><span class="n">build_generator</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">generator</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="p">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">=</span><span class="n">optimizer</span><span class="p">)</span>

        <span class="p">#</span> <span class="n">The</span> <span class="n">generator</span> <span class="n">takes</span> <span class="n">noise</span> <span class="k">as</span> <span class="n">input</span> <span class="k">and</span> <span class="n">generated</span> <span class="n">imgs</span>
        <span class="n">z</span> <span class="p">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="p">=(</span><span class="m">100</span><span class="p">,))</span>
        <span class="n">img</span> <span class="p">=</span> <span class="n">self</span><span class="p">.</span><span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

        <span class="p">#</span> <span class="n">For</span> <span class="n">the</span> <span class="n">combined</span> <span class="k">model</span> <span class="n">we</span> <span class="n">will</span> <span class="n">only</span> <span class="n">train</span> <span class="n">the</span> <span class="n">generator</span>
        <span class="n">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">trainable</span> <span class="p">=</span> <span class="nb">False</span>

        <span class="p">#</span> <span class="n">The</span> <span class="n">valid</span> <span class="n">takes</span> <span class="n">generated</span> <span class="n">images</span> <span class="k">as</span> <span class="n">input</span> <span class="k">and</span> <span class="n">determines</span> <span class="n">validity</span>
        <span class="n">valid</span> <span class="p">=</span> <span class="n">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

        <span class="p">#</span> <span class="n">The</span> <span class="n">combined</span> <span class="k">model</span>  <span class="p">(</span><span class="n">stacked</span> <span class="n">generator</span> <span class="k">and</span> <span class="n">discriminator</span><span class="p">)</span> <span class="n">takes</span>
        <span class="p">#</span> <span class="n">noise</span> <span class="k">as</span> <span class="n">input</span> <span class="p">=&gt;</span> <span class="n">generates</span> <span class="n">images</span> <span class="p">=&gt;</span> <span class="n">determines</span> <span class="n">validity</span>
        <span class="n">self</span><span class="p">.</span><span class="n">combined</span> <span class="p">=</span> <span class="k">Model</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">valid</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">combined</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="p">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">=</span><span class="n">optimizer</span><span class="p">)</span>

    <span class="n">def</span> <span class="n">build_generator</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>

        <span class="n">noise_shape</span> <span class="p">=</span> <span class="p">(</span><span class="m">100</span><span class="p">,)</span>

        <span class="k">model</span> <span class="p">=</span> <span class="n">Sequential</span><span class="p">()</span>

        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="m">256</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">=</span><span class="n">noise_shape</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">alpha</span><span class="p">=</span><span class="m">0.2</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">(</span><span class="n">momentum</span><span class="p">=</span><span class="m">0.8</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="m">512</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">alpha</span><span class="p">=</span><span class="m">0.2</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">(</span><span class="n">momentum</span><span class="p">=</span><span class="m">0.8</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="m">1024</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">alpha</span><span class="p">=</span><span class="m">0.2</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">(</span><span class="n">momentum</span><span class="p">=</span><span class="m">0.8</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="k">prod</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">img_shape</span><span class="p">),</span> <span class="n">activation</span><span class="p">=</span><span class="s1">'tanh'</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Reshape</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">img_shape</span><span class="p">))</span>

        <span class="k">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>

        <span class="n">noise</span> <span class="p">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="p">=</span><span class="n">noise_shape</span><span class="p">)</span>
        <span class="n">img</span> <span class="p">=</span> <span class="k">model</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>

        <span class="n">return</span> <span class="k">Model</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>

    <span class="n">def</span> <span class="n">build_discriminator</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>

        <span class="n">img_shape</span> <span class="p">=</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">img_rows</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">img_cols</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">channels</span><span class="p">)</span>

        <span class="k">model</span> <span class="p">=</span> <span class="n">Sequential</span><span class="p">()</span>

        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="p">=</span><span class="n">img_shape</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="m">512</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">alpha</span><span class="p">=</span><span class="m">0.2</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="m">256</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">alpha</span><span class="p">=</span><span class="m">0.2</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="n">activation</span><span class="p">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
        <span class="k">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>

        <span class="n">img</span> <span class="p">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="p">=</span><span class="n">img_shape</span><span class="p">)</span>
        <span class="n">validity</span> <span class="p">=</span> <span class="k">model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

        <span class="n">return</span> <span class="k">Model</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">validity</span><span class="p">)</span>

    <span class="n">def</span> <span class="n">train</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">=</span><span class="m">128</span><span class="p">,</span> <span class="n">save_interval</span><span class="p">=</span><span class="m">50</span><span class="p">):</span>

        <span class="p">#</span> <span class="nf">Load</span> <span class="n">the</span> <span class="n">dataset</span>
        <span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">_</span><span class="p">),</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="p">=</span> <span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>

        <span class="p">#</span> <span class="n">Rescale</span> <span class="p">-</span><span class="m">1</span> <span class="k">to</span> <span class="m">1</span>
        <span class="n">X_train</span> <span class="p">=</span> <span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="p">-</span> <span class="m">127.5</span><span class="p">)</span> <span class="p">/</span> <span class="m">127.5</span>
        <span class="n">X_train</span> <span class="p">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">axis</span><span class="p">=</span><span class="m">3</span><span class="p">)</span>

        <span class="n">half_batch</span> <span class="p">=</span> <span class="n">int</span><span class="p">(</span><span class="n">batch_size</span> <span class="p">/</span> <span class="m">2</span><span class="p">)</span>

        <span class="n">for</span> <span class="n">epoch</span> <span class="k">in</span> <span class="k">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>

            <span class="p">#</span> <span class="p">---------------------</span>
            <span class="p">#</span>  <span class="n">Train</span> <span class="n">Discriminator</span>
            <span class="p">#</span> <span class="p">---------------------</span>

            <span class="p">#</span> <span class="n">Select</span> <span class="n">a</span> <span class="nb">random</span> <span class="n">half</span> <span class="n">batch</span> <span class="k">of</span> <span class="n">images</span>
            <span class="n">idx</span> <span class="p">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="m">0</span><span class="p">],</span> <span class="n">half_batch</span><span class="p">)</span>
            <span class="n">imgs</span> <span class="p">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

            <span class="n">noise</span> <span class="p">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="p">(</span><span class="n">half_batch</span><span class="p">,</span> <span class="m">100</span><span class="p">))</span>

            <span class="p">#</span> <span class="n">Generate</span> <span class="n">a</span> <span class="n">half</span> <span class="n">batch</span> <span class="k">of</span> <span class="n">new</span> <span class="n">images</span>
            <span class="n">gen_imgs</span> <span class="p">=</span> <span class="n">self</span><span class="p">.</span><span class="n">generator</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>

            <span class="p">#</span> <span class="n">Train</span> <span class="n">the</span> <span class="n">discriminator</span>
            <span class="n">d_loss_real</span> <span class="p">=</span> <span class="n">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">train_on_batch</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">half_batch</span><span class="p">,</span> <span class="m">1</span><span class="p">)))</span>
            <span class="n">d_loss_fake</span> <span class="p">=</span> <span class="n">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">train_on_batch</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">half_batch</span><span class="p">,</span> <span class="m">1</span><span class="p">)))</span>
            <span class="n">d_loss</span> <span class="p">=</span> <span class="m">0.5</span> <span class="p">*</span> <span class="n">np</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">d_loss_real</span><span class="p">,</span> <span class="n">d_loss_fake</span><span class="p">)</span>


            <span class="p">#</span> <span class="p">---------------------</span>
            <span class="p">#</span>  <span class="n">Train</span> <span class="n">Generator</span>
            <span class="p">#</span> <span class="p">---------------------</span>

            <span class="n">noise</span> <span class="p">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="m">100</span><span class="p">))</span>

            <span class="p">#</span> <span class="n">The</span> <span class="n">generator</span> <span class="n">wants</span> <span class="n">the</span> <span class="n">discriminator</span> <span class="k">to</span> <span class="n">label</span> <span class="n">the</span> <span class="n">generated</span> <span class="n">samples</span>
            <span class="p">#</span> <span class="k">as</span> <span class="n">valid</span> <span class="p">(</span><span class="n">ones</span><span class="p">)</span>
            <span class="n">valid_y</span> <span class="p">=</span> <span class="n">np</span><span class="p">.</span><span class="k">array</span><span class="p">([</span><span class="m">1</span><span class="p">]</span> <span class="p">*</span> <span class="n">batch_size</span><span class="p">)</span>

            <span class="p">#</span> <span class="n">Train</span> <span class="n">the</span> <span class="n">generator</span>
            <span class="n">g_loss</span> <span class="p">=</span> <span class="n">self</span><span class="p">.</span><span class="n">combined</span><span class="p">.</span><span class="n">train_on_batch</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="n">valid_y</span><span class="p">)</span>

            <span class="p">#</span> <span class="n">Plot</span> <span class="n">the</span> <span class="n">progress</span>
            <span class="n">print</span> <span class="p">(</span><span class="s2">"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]"</span> <span class="p">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">d_loss</span><span class="p">[</span><span class="m">0</span><span class="p">],</span> <span class="m">100</span><span class="p">*</span><span class="n">d_loss</span><span class="p">[</span><span class="m">1</span><span class="p">],</span> <span class="n">g_loss</span><span class="p">))</span>

            <span class="p">#</span> <span class="k">If</span> <span class="n">at</span> <span class="n">save</span> <span class="n">interval</span> <span class="p">=&gt;</span> <span class="n">save</span> <span class="n">generated</span> <span class="n">image</span> <span class="n">samples</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="p">%</span> <span class="n">save_interval</span> <span class="p">==</span> <span class="m">0</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="n">save_imgs</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

    <span class="n">def</span> <span class="n">save_imgs</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="n">r</span><span class="p">,</span> <span class="n">c</span> <span class="p">=</span> <span class="m">5</span><span class="p">,</span> <span class="m">5</span>
        <span class="n">noise</span> <span class="p">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="p">(</span><span class="n">r</span> <span class="p">*</span> <span class="n">c</span><span class="p">,</span> <span class="m">100</span><span class="p">))</span>
        <span class="n">gen_imgs</span> <span class="p">=</span> <span class="n">self</span><span class="p">.</span><span class="n">generator</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>

        <span class="p">#</span> <span class="n">Rescale</span> <span class="n">images</span> <span class="m">0</span> <span class="p">-</span> <span class="m">1</span>
        <span class="n">gen_imgs</span> <span class="p">=</span> <span class="m">0.5</span> <span class="p">*</span> <span class="n">gen_imgs</span> <span class="p">+</span> <span class="m">0.5</span>

        <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="p">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
        <span class="n">cnt</span> <span class="p">=</span> <span class="m">0</span>
        <span class="n">for</span> <span class="n">i</span> <span class="k">in</span> <span class="k">range</span><span class="p">(</span><span class="n">r</span><span class="p">):</span>
            <span class="n">for</span> <span class="n">j</span> <span class="k">in</span> <span class="k">range</span><span class="p">(</span><span class="n">c</span><span class="p">):</span>
                <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">[</span><span class="n">cnt</span><span class="p">,</span> <span class="p">:,:,</span><span class="m">0</span><span class="p">],</span> <span class="n">cmap</span><span class="p">=</span><span class="s1">'gray'</span><span class="p">)</span>
                <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
                <span class="n">cnt</span> <span class="p">+=</span> <span class="m">1</span>
        <span class="n">fig</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">"gan/images/mnist_%d.png"</span> <span class="p">%</span> <span class="n">epoch</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="p">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">gan</span> <span class="p">=</span> <span class="n">GAN</span><span class="p">()</span>
    <span class="n">gan</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">=</span><span class="m">30000</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">=</span><span class="m">32</span><span class="p">,</span> <span class="n">save_interval</span><span class="p">=</span><span class="m">200</span><span class="p">)</span>
</code></pre></div></div>
<p><img src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/GANdancers.png" alt="GAN dancers"></p>
<p><em>Credit: The New Yorker</em></p>
<h2 id="resources-for-generative-networks">Resources for Generative Networks</h2>
<ul>
<li><a href="http://cs229.stanford.edu/notes/cs229-notes2.pdf">“Generative Learning algorithms” - Andrew Ng’s Stanford notes</a></li>
<li><a href="http://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes.pdf">On Discriminative vs. Generative classifiers: A comparison of logistic regression and naive Bayes, by Andrew Ng and Michael I. Jordan</a></li>
<li><a href="https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html">The Math Behind Generative Adversarial Networks</a></li>
</ul>
<p><img src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/stained_glass_cycleGAN.jpg" alt="stained glass cycle GAN"></p>
<h2 id="gan-use-cases">GAN Use Cases</h2>
<ul>
<li><a href="https://arxiv.org/abs/1605.05396">Text to Image Generation</a></li>
<li><a href="https://arxiv.org/abs/1611.07004">Image to Image Translation</a></li>
<li><a href="https://arxiv.org/abs/1609.04802">Increasing Image Resolution</a></li>
<li><a href="https://arxiv.org/abs/1511.06380">Predicting Next Video Frame</a></li>
</ul>
<h2 id="notable-papers-on-gans">Notable Papers on GANs</h2>
<ul>
<li>[Generative Adversarial Nets] <a href="https://arxiv.org/abs/1406.2661">[Paper]</a>
<a href="https://github.com/goodfeli/adversarial">[Code]</a>(Ian Goodfellow’s breakthrough paper)</li>
</ul>
<h3 id="unclassified-papers--resources">Unclassified Papers &amp; Resources</h3>
<ul>
<li>
<p><a href="https://github.com/soumith/ganhacks">GAN Hacks: How to Train a GAN? Tips and tricks to make GANs work</a></p>
</li>
<li>
<p>Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks] <a href="https://arxiv.org/abs/1506.05751">[Paper]</a><a href="https://github.com/facebook/eyescream">[Code]</a></p>
</li>
<li>
<p>[Adversarial Autoencoders] <a href="http://arxiv.org/abs/1511.05644">[Paper]</a><a href="https://github.com/musyoku/adversarial-autoencoder">[Code]</a></p>
</li>
<li>
<p>[Generating Images with Perceptual Similarity Metrics based on Deep Networks] <a href="https://arxiv.org/pdf/1602.02644v2.pdf">[Paper]</a></p>
</li>
<li>
<p>[Generating images with recurrent adversarial networks] <a href="https://arxiv.org/abs/1602.05110">[Paper]</a><a href="https://github.com/ofirnachum/sequence_gan">[Code]</a></p>
</li>
<li>
<p>[Generative Visual Manipulation on the Natural Image Manifold] <a href="https://people.eecs.berkeley.edu/~junyanz/projects/gvm/eccv16_gvm.pdf">[Paper]</a><a href="https://github.com/junyanz/iGAN">[Code]</a></p>
</li>
<li>
<p>[Learning What and Where to Draw] <a href="http://www.scottreed.info/files/nips2016.pdf">[Paper]</a><a href="https://github.com/reedscot/nips2016">[Code]</a></p>
</li>
<li>
<p>[Adversarial Training for Sketch Retrieval] <a href="http://link.springer.com/chapter/10.1007/978-3-319-46604-0_55">[Paper]</a></p>
</li>
<li>
<p>[Generative Image Modeling using Style and Structure Adversarial Networks] <a href="https://arxiv.org/pdf/1603.05631.pdf">[Paper]</a><a href="https://github.com/xiaolonw/ss-gan">[Code]</a></p>
</li>
<li>
<p>[Generative Adversarial Networks as Variational Training of Energy Based Models] <a href="http://www.mathpubs.com/detail/1611.01799v1/Generative-Adversarial-Networks-as-Variational-Training-of-Energy-Based-Models">[Paper]</a>(ICLR 2017)</p>
</li>
<li>
<p>[Synthesizing the preferred inputs for neurons in neural networks via deep generator networks] <a href="https://arxiv.org/pdf/1605.09304v5.pdf">[Paper]</a><a href="https://github.com/Evolving-AI-Lab/synthesizing">[Code]</a></p>
</li>
<li>
<p>[SalGAN: Visual Saliency Prediction with Generative Adversarial Networks] <a href="https://arxiv.org/abs/1701.01081">[Paper]</a><a href="https://github.com/imatge-upc/saliency-salgan-2017">[Code]</a></p>
</li>
<li>
<p>[Adversarial Feature Learning] <a href="https://arxiv.org/abs/1605.09782">[Paper]</a></p>
</li>
</ul>
<h3 id="generating-high-quality-images">Generating High-Quality Images</h3>
<ul>
<li>
<p>[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks] <a href="https://arxiv.org/abs/1511.06434">[Paper]</a><a href="https://github.com/jacobgil/keras-dcgan">[Code]</a>(Gan with convolutional networks)(ICLR)</p>
</li>
<li>
<p>[Generative Adversarial Text to Image Synthesis] <a href="https://arxiv.org/abs/1605.05396">[Paper]</a><a href="https://github.com/reedscot/icml2016">[Code]</a><a href="https://github.com/paarthneekhara/text-to-image">[Code]</a></p>
</li>
<li>
<p>[Improved Techniques for Training GANs] <a href="https://arxiv.org/abs/1606.03498">[Paper]</a><a href="https://github.com/openai/improved-gan">[Code]</a>(Goodfellow’s paper)</p>
</li>
<li>
<p>[Plug &amp; Play Generative Networks: Conditional Iterative Generation of Images in Latent Space] <a href="https://arxiv.org/abs/1612.00005v1">[Paper]</a><a href="https://github.com/Evolving-AI-Lab/ppgn">[Code]</a></p>
</li>
<li>
<p>[StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks] <a href="https://arxiv.org/pdf/1612.03242v1.pdf">[Paper]</a><a href="https://github.com/hanzhanggit/StackGAN">[Code]</a></p>
</li>
<li>
<p>[Improved Training of Wasserstein GANs] <a href="https://arxiv.org/abs/1704.00028">[Paper]</a><a href="https://github.com/igul222/improved_wgan_training">[Code]</a></p>
</li>
<li>
<p>[Boundary Equibilibrium Generative Adversarial Networks Implementation in Tensorflow] <a href="https://arxiv.org/abs/1703.10717">[Paper]</a><a href="https://github.com/artcg/BEGAN">[Code]</a></p>
</li>
<li>
<p>[Progressive Growing of GANs for Improved Quality, Stability, and Variation ] <a href="http://research.nvidia.com/publication/2017-10_Progressive-Growing-of">[Paper]</a><a href="https://github.com/tkarras/progressive_growing_of_gans">[Code]</a></p>
</li>
</ul>
<h3 id="semi-supervised-learning">Semi-supervised learning</h3>
<ul>
<li>
<p>[Adversarial Training Methods for Semi-Supervised Text Classification] <a href="https://arxiv.org/abs/1605.07725">[Paper]</a><a href="https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/adversarial-text-classification.md">[Note]</a>( Ian Goodfellow Paper)</p>
</li>
<li>
<p>[Improved Techniques for Training GANs] <a href="https://arxiv.org/abs/1606.03498">[Paper]</a><a href="https://github.com/openai/improved-gan">[Code]</a>(Goodfellow’s paper)</p>
</li>
<li>
<p>[Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks] <a href="https://arxiv.org/abs/1511.06390">[Paper]</a>(ICLR)</p>
</li>
<li>
<p>[Semi-Supervised QA with Generative Domain-Adaptive Nets] <a href="https://arxiv.org/abs/1702.02206">[Paper]</a>(ACL 2017)</p>
</li>
</ul>
<h3 id="ensembles">Ensembles</h3>
<ul>
<li>[AdaGAN: Boosting Generative Models] <a href="https://arxiv.org/abs/1701.02386">[Paper]</a>[[Code]]（Google Brain）</li>
</ul>
<h3 id="clustering">Clustering</h3>
<ul>
<li>[Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks] <a href="https://arxiv.org/abs/1511.06390">[Paper]</a>(ICLR)</li>
</ul>
<h3 id="image-blending">Image blending</h3>
<ul>
<li>[GP-GAN: Towards Realistic High-Resolution Image Blending] <a href="https://arxiv.org/abs/1703.07195">[Paper]</a><a href="https://github.com/wuhuikai/GP-GAN">[Code]</a></li>
</ul>
<h3 id="image-inpainting">Image Inpainting</h3>
<ul>
<li>
<p>[Semantic Image Inpainting with Perceptual and Contextual Losses] <a href="https://arxiv.org/abs/1607.07539">[Paper]</a><a href="https://github.com/bamos/dcgan-completion.tensorflow">[Code]</a>(CVPR 2017)</p>
</li>
<li>
<p>[Context Encoders: Feature Learning by Inpainting] <a href="https://arxiv.org/abs/1604.07379">[Paper]</a><a href="https://github.com/jazzsaxmafia/Inpainting">[Code]</a></p>
</li>
<li>
<p>[Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks] <a href="https://arxiv.org/abs/1611.06430v1">[Paper]</a></p>
</li>
<li>
<p>[Generative face completion] <a href="https://drive.google.com/file/d/0B8_MZ8a8aoSeenVrYkpCdnFRVms/edit">[Paper]</a><a href="https://github.com/Yijunmaverick/GenerativeFaceCompletion">[Code]</a>(CVPR2017)</p>
</li>
<li>
<p>[Globally and Locally Consistent Image Completion] <a href="http://hi.cs.waseda.ac.jp/~iizuka/projects/completion/en/">[MainPAGE]</a>(SIGGRAPH 2017)</p>
</li>
</ul>
<h3 id="joint-probability">Joint Probability</h3>
<ul>
<li>[Adversarially Learned Inference]<a href="https://arxiv.org/abs/1606.00704">[Paper]</a><a href="https://github.com/IshmaelBelghazi/ALI">[Code]</a></li>
</ul>
<h3 id="super-resolution">Super-Resolution</h3>
<ul>
<li>
<p>[Image super-resolution through deep learning ]<a href="https://github.com/david-gpu/srez">[Code]</a>(Just for face dataset)</p>
</li>
<li>
<p>[Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network] <a href="https://arxiv.org/abs/1609.04802">[Paper]</a><a href="https://github.com/leehomyc/Photo-Realistic-Super-Resoluton">[Code]</a>（Using Deep residual network）</p>
</li>
<li>
<p>[EnhanceGAN] <a href="https://medium.com/@richardherbert/faces-from-noise-super-enhancing-8x8-images-with-enhancegan-ebda015bb5e0#.io6pskvin">Docs</a>[[Code]]</p>
</li>
</ul>
<h3 id="de-occlusion">De-occlusion</h3>
<ul>
<li>[Robust LSTM-Autoencoders for Face De-Occlusion in the Wild] <a href="https://arxiv.org/abs/1612.08534">[Paper]</a></li>
</ul>
<h3 id="semantic-segmentation">Semantic Segmentation</h3>
<ul>
<li>
<p>[Adversarial Deep Structural Networks for Mammographic Mass Segmentation] <a href="https://arxiv.org/abs/1612.05970">[Paper]</a><a href="https://github.com/wentaozhu/adversarial-deep-structural-networks">[Code]</a></p>
</li>
<li>
<p>[Semantic Segmentation using Adversarial Networks] <a href="https://arxiv.org/abs/1611.08408">[Paper]</a>（Soumith’s paper）</p>
</li>
</ul>
<h3 id="object-detection">Object Detection</h3>
<ul>
<li>
<p>[Perceptual generative adversarial networks for small object detection] <a href="https://arxiv.org/abs/1706.05274v2">[Paper]</a>(CVPR 2017)</p>
</li>
<li>
<p>[A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection] <a href="http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf">[Paper]</a><a href="https://github.com/xiaolonw/adversarial-frcnn">[Code]</a>(CVPR2017)</p>
</li>
</ul>
<h3 id="rnn-gans">RNN-GANs</h3>
<ul>
<li>[C-RNN-GAN: Continuous recurrent neural networks with adversarial training] <a href="https://arxiv.org/abs/1611.09904">[Paper]</a><a href="https://github.com/olofmogren/c-rnn-gan">[Code]</a></li>
</ul>
<h3 id="conditional-adversarial-nets">Conditional Adversarial Nets</h3>
<ul>
<li>
<p>[Conditional Generative Adversarial Nets] <a href="https://arxiv.org/abs/1411.1784">[Paper]</a><a href="https://github.com/zhangqianhui/Conditional-Gans">[Code]</a></p>
</li>
<li>
<p>[InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets] <a href="https://arxiv.org/abs/1606.03657">[Paper]</a><a href="https://github.com/buriburisuri/supervised_infogan">[Code]</a><a href="https://github.com/openai/InfoGAN">[Code]</a></p>
</li>
<li>
<p>[Conditional Image Synthesis With Auxiliary Classifier GANs] <a href="https://arxiv.org/abs/1610.09585">[Paper]</a><a href="https://github.com/buriburisuri/ac-gan">[Code]</a>(GoogleBrain ICLR 2017)</p>
</li>
<li>
<p>[Pixel-Level Domain Transfer] <a href="https://arxiv.org/pdf/1603.07442v2.pdf">[Paper]</a><a href="https://github.com/fxia22/pldtgan">[Code]</a></p>
</li>
<li>
<p>[Invertible Conditional GANs for image editing] <a href="https://arxiv.org/abs/1611.06355">[Paper]</a><a href="https://github.com/Guim3/IcGAN">[Code]</a></p>
</li>
<li>
<p>[Plug &amp; Play Generative Networks: Conditional Iterative Generation of Images in Latent Space] <a href="https://arxiv.org/abs/1612.00005v1">[Paper]</a><a href="https://github.com/Evolving-AI-Lab/ppgn">[Code]</a></p>
</li>
<li>
<p>[StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks] <a href="https://arxiv.org/pdf/1612.03242v1.pdf">[Paper]</a><a href="https://github.com/hanzhanggit/StackGAN">[Code]</a></p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1801.07736">MaskGAN: Better Text Generation via Filling in the <strong>__</strong></a> Goodfellow et al</p>
</li>
</ul>
<h3 id="video-prediction--generation">Video Prediction &amp; Generation</h3>
<ul>
<li>
<p>[Deep multi-scale video prediction beyond mean square error] <a href="https://arxiv.org/abs/1511.05440">[Paper]</a><a href="https://github.com/dyelax/Adversarial_Video_Generation">[Code]</a>(Yann LeCun’s paper)</p>
</li>
<li>
<p>[Generating Videos with Scene Dynamics] <a href="https://arxiv.org/abs/1609.02612">[Paper]</a><a href="http://web.mit.edu/vondrick/tinyvideo/">[Web]</a><a href="https://github.com/cvondrick/videogan">[Code]</a></p>
</li>
<li>
<p>[MoCoGAN: Decomposing Motion and Content for Video Generation] <a href="https://arxiv.org/abs/1707.04993">[Paper]</a></p>
</li>
</ul>
<h3 id="texture-synthesis--style-transfer">Texture Synthesis &amp; Style Transfer</h3>
<ul>
<li>[Precomputed real-time texture synthesis with markovian generative adversarial networks] <a href="https://arxiv.org/abs/1604.04382">[Paper]</a><a href="https://github.com/chuanli11/MGANs">[Code]</a>(ECCV 2016)</li>
</ul>
<h3 id="image-translation">Image Translation</h3>
<ul>
<li>
<p>[Unsupervised cross-domain image generation] <a href="https://arxiv.org/abs/1611.02200">[Paper]</a><a href="https://github.com/yunjey/domain-transfer-network">[Code]</a></p>
</li>
<li>
<p>[Image-to-image translation using conditional adversarial nets] <a href="https://arxiv.org/pdf/1611.07004v1.pdf">[Paper]</a><a href="https://github.com/phillipi/pix2pix">[Code]</a><a href="https://github.com/yenchenlin/pix2pix-tensorflow">[Code]</a></p>
</li>
<li>
<p>[Learning to Discover Cross-Domain Relations with Generative Adversarial Networks] <a href="https://arxiv.org/abs/1703.05192">[Paper]</a><a href="https://github.com/carpedm20/DiscoGAN-pytorch">[Code]</a></p>
</li>
<li>
<p>[Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks] <a href="https://junyanz.github.io/CycleGAN/">[Paper]</a><a href="https://github.com/junyanz/CycleGAN">[Code]</a></p>
</li>
<li>
<p>[CoGAN: Coupled Generative Adversarial Networks] <a href="https://arxiv.org/abs/1606.07536">[Paper]</a><a href="https://github.com/andrewliao11/CoGAN-tensorflow">[Code]</a>(NIPS 2016)</p>
</li>
<li>
<p>[Unsupervised Image-to-Image Translation with Generative Adversarial Networks] <a href="https://arxiv.org/pdf/1701.02676.pdf">[Paper]</a></p>
</li>
<li>
<p>[Unsupervised Image-to-Image Translation Networks] <a href="https://arxiv.org/abs/1703.00848">[Paper]</a></p>
</li>
<li>
<p>[Triangle Generative Adversarial Networks] <a href="https://arxiv.org/abs/1709.06548">[Paper]</a></p>
</li>
</ul>
<h3 id="gan-theory">GAN Theory</h3>
<ul>
<li>
<p>[Energy-based generative adversarial network] <a href="https://arxiv.org/pdf/1609.03126v2.pdf">[Paper]</a><a href="https://github.com/buriburisuri/ebgan">[Code]</a>(Lecun paper)</p>
</li>
<li>
<p>[Improved Techniques for Training GANs] <a href="https://arxiv.org/abs/1606.03498">[Paper]</a><a href="https://github.com/openai/improved-gan">[Code]</a>(Goodfellow’s paper)</p>
</li>
<li>
<p>[Mode Regularized Generative Adversarial Networks] <a href="https://openreview.net/pdf?id=HJKkY35le">[Paper]</a>(Yoshua Bengio , ICLR 2017)</p>
</li>
<li>
<p>[Improving Generative Adversarial Networks with Denoising Feature Matching] <a href="https://openreview.net/pdf?id=S1X7nhsxl">[Paper]</a><a href="https://github.com/hvy/chainer-gan-denoising-feature-matching">[Code]</a>(Yoshua Bengio , ICLR 2017)</p>
</li>
<li>
<p>[Sampling Generative Networks] <a href="https://arxiv.org/abs/1609.04468">[Paper]</a><a href="https://github.com/dribnet/plat">[Code]</a></p>
</li>
<li>
<p>[How to train Gans] <a href="https://github.com/soumith/ganhacks#authors">[Docu]</a></p>
</li>
<li>
<p>[Towards Principled Methods for Training Generative Adversarial Networks] <a href="http://openreview.net/forum?id=Hk4_qw5xe">[Paper]</a>(ICLR 2017)</p>
</li>
<li>
<p>[Unrolled Generative Adversarial Networks] <a href="https://arxiv.org/abs/1611.02163">[Paper]</a><a href="https://github.com/poolio/unrolled_gan">[Code]</a>(ICLR 2017)</p>
</li>
<li>
<p>[Least Squares Generative Adversarial Networks] <a href="https://arxiv.org/abs/1611.04076">[Paper]</a><a href="https://github.com/pfnet-research/chainer-LSGAN">[Code]</a>(ICCV 2017)</p>
</li>
<li>
<p>[Wasserstein GAN] <a href="https://arxiv.org/abs/1701.07875">[Paper]</a><a href="https://github.com/martinarjovsky/WassersteinGAN">[Code]</a></p>
</li>
<li>
<p>[Improved Training of Wasserstein GANs] <a href="https://arxiv.org/abs/1704.00028">[Paper]</a><a href="https://github.com/igul222/improved_wgan_training">[Code]</a>(The improve of wgan)</p>
</li>
<li>
<p>[Towards Principled Methods for Training Generative Adversarial Networks] <a href="https://arxiv.org/abs/1701.04862">[Paper]</a></p>
</li>
<li>
<p>[Generalization and Equilibrium in Generative Adversarial Nets] <a href="https://arxiv.org/abs/1703.00573">[Paper]</a>（ICML 2017）</p>
</li>
</ul>
<h3 id="3-dimensional-gans">3-Dimensional GANs</h3>
<ul>
<li>
<p>[Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling] <a href="https://arxiv.org/abs/1610.07584">[Paper]</a><a href="http://3dgan.csail.mit.edu/">[Web]</a><a href="https://github.com/zck119/3dgan-release">[Code]</a>(2016 NIPS)</p>
</li>
<li>
<p>[Transformation-Grounded Image Generation Network for Novel 3D View Synthesis] <a href="http://www.cs.unc.edu/~eunbyung/tvsn/">[Web]</a>(CVPR 2017)</p>
</li>
</ul>
<h3 id="music">Music</h3>
<ul>
<li>[MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation using 1D and 2D Conditions] <a href="https://arxiv.org/abs/1703.10847">[Paper]</a><a href="https://richardyang40148.github.io/TheBlog/midinet_arxiv_demo.html">[HOMEPAGE]</a></li>
</ul>
<h3 id="face-generation--editing">Face Generation &amp; Editing</h3>
<ul>
<li>
<p>[Autoencoding beyond pixels using a learned similarity metric] <a href="https://arxiv.org/abs/1512.09300">[Paper]</a><a href="https://github.com/andersbll/autoencoding_beyond_pixels">[Code]</a><a href="https://github.com/zhangqianhui/vae-gan-tensorflow">[Tensorflow code]</a></p>
</li>
<li>
<p>[Coupled Generative Adversarial Networks] <a href="http://mingyuliu.net/">[Paper]</a><a href="https://github.com/mingyuliutw/CoGAN">[Caffe Code]</a><a href="https://github.com/andrewliao11/CoGAN-tensorflow">[Tensorflow Code]</a>（NIPS）</p>
</li>
<li>
<p>[Invertible Conditional GANs for image editing] <a href="https://drive.google.com/file/d/0B48XS5sLi1OlRkRIbkZWUmdoQmM/view">[Paper]</a><a href="https://github.com/Guim3/IcGAN">[Code]</a></p>
</li>
<li>
<p>[Learning Residual Images for Face Attribute Manipulation] <a href="https://arxiv.org/abs/1612.05363">[Paper]</a><a href="https://github.com/Zhongdao/FaceAttributeManipulation">[Code]</a>(CVPR 2017)</p>
</li>
<li>
<p>[Neural Photo Editing with Introspective Adversarial Networks] <a href="https://arxiv.org/abs/1609.07093">[Paper]</a><a href="https://github.com/ajbrock/Neural-Photo-Editor">[Code]</a>(ICLR 2017)</p>
</li>
<li>
<p>[Neural Face Editing with Intrinsic Image Disentangling] <a href="https://arxiv.org/abs/1704.04131">[Paper]</a>(CVPR 2017)</p>
</li>
<li>
<p>[GeneGAN: Learning Object Transfiguration and Attribute Subspace from Unpaired Data ] <a href="https://arxiv.org/abs/1705.04932">[Paper]</a>(BMVC 2017)<a href="https://github.com/Prinsphield/GeneGAN">[Code]</a></p>
</li>
<li>
<p>[Beyond Face Rotation: Global and Local Perception GAN for Photorealistic and Identity Preserving Frontal View Synthesis] <a href="https://arxiv.org/abs/1704.04086">[Paper]</a>(ICCV 2017)</p>
</li>
</ul>
<h3 id="for-discrete-distributions">For Discrete Distributions</h3>
<ul>
<li>
<p>[Maximum-Likelihood Augmented Discrete Generative Adversarial Networks] <a href="https://arxiv.org/abs/1702.07983v1">[Paper]</a></p>
</li>
<li>
<p>[Boundary-Seeking Generative Adversarial Networks] <a href="https://arxiv.org/abs/1702.08431">[Paper]</a></p>
</li>
<li>
<p>[GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution] <a href="https://arxiv.org/abs/1611.04051">[Paper]</a></p>
</li>
</ul>
<h3 id="improving-classification--recognition">Improving Classification &amp; Recognition</h3>
<ul>
<li>
<p>[Generative OpenMax for Multi-Class Open Set Classification] <a href="https://arxiv.org/pdf/1707.07418.pdf">[Paper]</a>(BMVC 2017)</p>
</li>
<li>
<p>[Controllable Invariance through Adversarial Feature Learning] <a href="https://arxiv.org/abs/1705.11122">[Paper]</a><a href="https://github.com/github-pengge/adversarial_invariance_feature_learning">[Code]</a>(NIPS 2017)</p>
</li>
<li>
<p>[Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro] <a href="https://arxiv.org/abs/1701.07717">[Paper]</a><a href="https://github.com/layumi/Person-reID_GAN">[Code]</a> (ICCV2017)</p>
</li>
<li>
<p>[Learning from Simulated and Unsupervised Images through Adversarial Training] <a href="https://arxiv.org/abs/1612.07828">[Paper]</a><a href="https://github.com/carpedm20/simulated-unsupervised-tensorflow">[Code]</a>（Apple paper, CVPR 2017 Best Paper）</p>
</li>
</ul>
<h3 id="projects">Projects</h3>
<ul>
<li>
<p>[cleverhans] <a href="https://github.com/openai/cleverhans">[Code]</a>(A library for benchmarking vulnerability to adversarial examples)</p>
</li>
<li>
<p>[reset-cppn-gan-tensorflow] <a href="https://github.com/hardmaru/resnet-cppn-gan-tensorflow">[Code]</a>(Using Residual Generative Adversarial Networks and Variational Auto-encoder techniques to produce high-resolution images)</p>
</li>
<li>
<p>[HyperGAN] <a href="https://github.com/255bits/HyperGAN">[Code]</a>(Open source GAN focused on scale and usability)</p>
</li>
</ul>
<h3 id="tutorials">Tutorials</h3>
<ul>
<li>
<p>[1] <a href="http://www.iangoodfellow.com/slides/2016-12-04-NIPS.pdf">Ian Goodfellow’s GAN Slides</a> (NIPS Goodfellow Slides)<a href="http://c.m.163.com/news/a/C7UE2MLT0511AQHO.html?spss=newsapp&amp;spsw=1">[Chinese Trans]</a><a href="https://arxiv.org/pdf/1701.00160v1.pdf">details</a></p>
</li>
<li>
<p>[2] <a href="https://drive.google.com/file/d/0BxKBnD5y2M8NbzBUbXRwUDBZOVU/view">PDF</a>(NIPS Lecun Slides)</p>
</li>
<li>
<p>[3] <a href="https://sites.google.com/view/iccv-2017-gans/schedule">ICCV 2017 Tutorial About GANS</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="w-section section-cta">
<div class="w-container container-cta">
<div class="w-row"><img width="42" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/hr_gradient.png" class="hr-center">
<h1 class="body-h2-cta">Free Consultation</h1>
<p class="body-h3-cta">Schedule a 30-minute Q&amp;A with our AI experts.</p>
<a href="https://skymind.ai/contact" class="w-button button-contactcta">TALK TO A SKYMIND EXPERT</a>
</div>
</div>
</div>
<div class="w-section section-footer">
<div id="footer">
<div class="w-container container-footer"><img src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/logo_footer.svg" class="img-logo--footer">
<div class="w-row row-2">
<div class="w-col w-col-3">
<h1 class="footer-heading">Company</h1>
<ul class="w-list-unstyled ul-footer">
<li><a class="footer-link" href="https://skymind.ai/about">About</a>
</li>
<li><a class="footer-link" href="https://drive.google.com/drive/folders/1S9n-mdI17euhJMDKP-x0T05E1lGY1ly3" target="_blank">Press Kit</a>
</li>
<li><a class="footer-link" href="https://skymind.ai/contact">Contact Us</a>
</li>
<li><a class="footer-link" href="https://skymind.ai/press">Press</a>
</li>
<li><a class="footer-link" href="https://skymind.ai/privacy">Privacy</a>
</li>
</ul>
</div>
<div class="w-col w-col-2">
<h1 class="footer-heading">What We Offer</h1>
<ul class="w-list-unstyled ul-footer">
<li><a class="footer-link" href="https://skymind.ai/platform">AI Platform</a>
</li>
<li><a class="footer-link" href="https://skymind.ai/subscription">Subscriptions</a>
</li>
</ul>
</div>
<div class="w-col w-col-2">
<h1 class="footer-heading">Open-Source</h1>
<ul class="w-list-unstyled ul-footer">
<li><a class="footer-link" target="_blank" href="http://deeplearning4j.org/">Deeplearning4j</a>
</li>
<li><a class="footer-link" target="_blank" href="http://nd4j.org/">ND4J</a>
</li>
<li><a class="footer-link" target="_blank" href="http://deeplearning4j.org/datavec">DataVec</a>
</li>
<li><a class="footer-link" target="_blank" href="https://github.com/bytedeco/javacpp">JavaCPP</a>
</li>
</ul>
</div>
<div class="w-col w-col-2">
<h1 class="footer-heading">Follow Us</h1>
<ul class="w-list-unstyled ul-footer">
<li><a class="footer-link" target="_blank" href="https://www.facebook.com/deeplearning4j/">Facebook</a>
</li>
<li><a class="footer-link" target="_blank" href="https://twitter.com/deeplearning4j">Twitter</a>
</li>
<li><a class="footer-link" target="_blank" href="https://www.linkedin.com/company/skymind-io">Linkedin</a>
</li>
<li><a class="footer-link" target="_blank" href="https://gitter.im/deeplearning4j/deeplearning4j">Gitter</a>
</li>
</ul>
</div>
<div class="w-col w-col-3 subscribe-form">
<h1 class="footer-heading">Subscribe to our mailing list</h1>
<iframe src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/d9xsrj.html" width="100%" height="130px" type="text/html" frameborder="0" allowtransparency="true"></iframe>
</div>
</div>
</div>
</div>
</div>

<script type="text/javascript" id="" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/pa-5a1c929041f2c2000700004d.js"></script><script type="text/javascript" id="">piAId="457082";piCId="67370";piHostname="pi.pardot.com";(function(){function a(){var b=document.createElement("script");b.type="text/javascript";b.src=("https:"==document.location.protocol?"https://pi":"http://cdn")+".pardot.com/pd.js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(b,a)}window.attachEvent?window.attachEvent("onload",a):window.addEventListener("load",a,!1)})();</script>
<script type="text/javascript" id="hs-script-loader" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/2179705(1).js"></script><script>
$(document).ready(function() {
// Tooltip only Text
$('.masterTooltip').hover(function(){
        // Hover over code
        var title = $(this).attr('title');
        $(this).data('tipText', title).removeAttr('title');
        $('<p class="tooltip"></p>')
        .text(title)
        .appendTo('body')
        .fadeIn('slow');
}, function() {
        // Hover out code
        $(this).attr('title', $(this).data('tipText'));
        $('.tooltip').remove();
}).mousemove(function(e) {
        var mousex = e.pageX + 20; //Get X coordinates
        var mousey = e.pageY + 10; //Get Y coordinates
        $('.tooltip')
        .css({ top: mousey, left: mousex })
});
});
</script>
<script type="text/javascript" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/jquery.min.js"></script>

<script type="text/javascript" src="./A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) _ Skymind_files/skymind.js"></script>
<!--[if lte IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->
<script type="text/javascript">
    function wikiSearchFn() {
      // Declare variables
      var input, filter, ul, li, a, i;
      input = document.getElementById('wiki-search-input');
      filter = input.value.toUpperCase();
      ul = document.getElementById("wiki-links-ul");
      li = ul.getElementsByTagName('li');

      // Loop through all list items, and hide those who don't match the search query
      for (i = 0; i < li.length; i++) {
          a = li[i].getElementsByTagName("a")[0];
          if (a.innerHTML.toUpperCase().indexOf(filter) > -1) {
              li[i].style.display = "";
          } else {
              li[i].style.display = "none";
          }
      }
    }
  </script>


<style id="wistia_16_style" type="text/css" class="wistia_injected_style">
@font-face {
font-family: 'WistiaPlayerOverpassNumbers';
src: url(data:application/x-font-ttf;charset=utf-8;base64,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);
}
</style></body></html>